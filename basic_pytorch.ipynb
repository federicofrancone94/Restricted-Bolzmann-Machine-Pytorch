{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kickstart RBM Notebook\n",
    "- Using an RBM implementation found on github, we perform some preliminary tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import numpy as np\n",
    "import re \n",
    "\n",
    "from src.rbm_example import RBM\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_validate, ParameterGrid\n",
    "\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_ticks_ecc(title, xlabel, ylabel, new_fig= True , figsize= (10,6), title_size=18):\n",
    "    if new_fig== True:\n",
    "        plt.figure(figsize=figsize)\n",
    "        \n",
    "    plt.title(title, color= 'xkcd:pale red', fontsize= title_size, pad= 13, fontweight= 'bold')\n",
    "    plt.xlabel(xlabel, color='xkcd:pale red', fontsize= 14, fontweight= 'bold')\n",
    "    plt.ylabel(ylabel, color= 'xkcd:pale red', fontsize= 14, fontweight= 'bold')\n",
    "    plt.xticks(fontsize=12, color= 'xkcd:cadet blue')\n",
    "    plt.yticks(fontsize=12, color= 'xkcd:cadet blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduced_models_lasso(values_C, \n",
    "                         train, \n",
    "                         ytrain, \n",
    "                         random_state=42, \n",
    "                         min_n_feats=12, \n",
    "                         max_n_feats=70,\n",
    "                         solver= 'liblinear'):\n",
    "    \n",
    "        \"\"\"\n",
    "        INPUTS:\n",
    "           values_C: list or array of C values to try\n",
    "           train and test: train and test dataset to use, all numerical (cat variables must be encoded)\n",
    "           random_state: initialization for the minimization problem\n",
    "\n",
    "           OUTPUT:\n",
    "           Data frame having for each row the chosen C value, the number of features selected and the list of those\"\"\"\n",
    "\n",
    "        X_train = train\n",
    "        values_C= [round(val, 5) for val in values_C] ## rounding it to 5 decimals\n",
    "        #################################################\n",
    "\n",
    "        reduced_lasso = {}\n",
    "        len_val_C = 0\n",
    "\n",
    "        for c in values_C:\n",
    "                lasso = SelectFromModel(\n",
    "                        LogisticRegression(C=c, penalty='l1', solver= solver, random_state=random_state))\n",
    "                lasso.fit(X_train, ytrain)\n",
    "                feats = list(X_train.columns[lasso.get_support()])\n",
    "                reduced_lasso[c] = [sum(lasso.get_support()), feats]\n",
    "\n",
    "                if len(feats) != X_train.shape[1]:\n",
    "                        len_val_C += 1\n",
    "\n",
    "        n_feats = [reduced_lasso[c][0] for c in values_C]\n",
    "        list_feats = [reduced_lasso[c][1] for c in values_C]\n",
    "\n",
    "        reduced_lasso = pd.DataFrame(n_feats, columns=['n_feats_selected'], index=values_C)\n",
    "        reduced_lasso['list_features'] = list_feats\n",
    "        final_index = reduced_lasso[['n_feats_selected']].drop_duplicates(keep='first').index\n",
    "        reduced_lasso = reduced_lasso.loc[final_index]\n",
    "        reduced_lasso = reduced_lasso[reduced_lasso['n_feats_selected'] > 2]\n",
    "\n",
    "        print('Initial features =', X_train.shape[1])\n",
    "\n",
    "        reduced_lasso = reduced_lasso[(reduced_lasso['n_feats_selected'] > min_n_feats) & (\n",
    "                reduced_lasso['n_feats_selected'] < max_n_feats)]\n",
    "\n",
    "        return reduced_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_no_cv(estimator, X_train, X_test, ytrain, ytest, param_grid=None,\n",
    "                    print_model=True):\n",
    "\n",
    "        \"\"\"HIGH LEVEL EXPLANATION:\n",
    "        to be stick to US procedure, we have to select parameters this way: for each parameters combination, you see the Train AUC and Test AUC,\n",
    "        then you choose the best model which has a sufficient small gap (like 1% or 2% difference).\n",
    "        The same function with CROSS VALIDATION is given after.\n",
    "\n",
    "        This function allows to just set a parameter grid and the model which is wanted to use and returns Train AUC and Test AUC for each iteration,\n",
    "        specifying the current parameters.\n",
    "\n",
    "        INPUT PARAMETERS:\n",
    "                estimator: classifier which is wanted to use\n",
    "                X_train, X_test: train and test data, without NA values and categorical features and scaled if necessary.\n",
    "                param_grid: dictionary of parameters\n",
    "                print_model: [True, False]. If True, at each iteration, the model is returned. It just helps to verify whether at each iteration the parameters are chaning\n",
    "\n",
    "        OUTPUT:\n",
    "               a dataframe with all the combinations of parameters with respective Train and Test AUC scores, plus the ROC plots\n",
    "               The decision of the \"best\" parameters has to be taken manually looking at the results\n",
    "\n",
    "        EXAMPLE USAGE:\n",
    "                rf= RandomForestClassifier(n_estimators= 10, criterion= 'gini', random_state=0, class_weight= 'balanced')\n",
    "\n",
    "                param_rf= {\n",
    "                    \"criterion\": ['gini'],\n",
    "                    \"n_estimators\" : [300],\n",
    "                    \"min_impurity_decrease\" :  [1e-03, 1e-06],\n",
    "                    \"min_samples_leaf\": [20, 40],\n",
    "                    \"max_depth\": [3, 6] }\n",
    "\n",
    "                best_rf = run_model_no_cv(estimator=rf, X_train= final_train, X_test= final_test, param_grid= param_rf)  #best_rf is a dataframe\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        print('\\033[1m Initial X_train e X_test shapes are: ', X_train.shape, X_test.shape, '\\033[0m \\n')\n",
    "        temp = time.time()\n",
    "\n",
    "\n",
    "        if param_grid is None:\n",
    "\n",
    "                estimator.fit(X_train, ytrain, )\n",
    "\n",
    "                preds = estimator.predict(X_test)\n",
    "                print('execution time (min)=', round((time.time() - temp) / 60, 1), ' finished at ', datetime.today())\n",
    "                #summary_classifier(estimator, X_train, ytrain, ytest, preds)\n",
    "\n",
    "                proba_train_y = estimator.predict_proba(X_train)\n",
    "                proba_test_y = estimator.predict_proba(X_test)\n",
    "\n",
    "                roc_auc_test = roc_auc_score(ytest, proba_test_y )\n",
    "                roc_auc_train = roc_auc_score(ytrain, proba_train_y)\n",
    "                fpr, tpr, _ = roc_curve(ytest, proba_test_y )\n",
    "                fpr_tr, tpr_tr, _ = roc_curve(ytrain, proba_train_y)\n",
    "\n",
    "                title_ticks_ecc('Receiver Operating Characteristic', 'True Positive Rate', 'False Positive Rate',\n",
    "                                figsize=(10, 6))\n",
    "                plt.plot(fpr, tpr, label='Test AUC ROC = {0}'.format(round(roc_auc_test, 4)))\n",
    "                plt.plot(fpr_tr, tpr_tr, label='Train AUC = {0}'.format(round(roc_auc_train, 4)))\n",
    "                plt.legend(loc='lower right', fontsize=10)\n",
    "                plt.plot([0, 1], [0, 1], 'r--')\n",
    "                plt.close()\n",
    "\n",
    "                return estimator\n",
    "\n",
    "        else:\n",
    "                # print(X_train.columns)\n",
    "                models = {}\n",
    "                iteration = 1\n",
    "\n",
    "                for diz_params in list(ParameterGrid(param_grid)):\n",
    "                        print('\\n\\t \\033[1mITERATION {}/{} \\033[0m'.format(iteration,\n",
    "                                                                           len(list(ParameterGrid(param_grid)))))\n",
    "                        print('\\t Current Grid of Parameters is {}'.format(diz_params))\n",
    "\n",
    "#                         if catb == True:\n",
    "#                                 est = cb.CatBoostClassifier()\n",
    "#                                 est.set_params(**diz_params)\n",
    "#                                 est.fit(X_train, ytrain, cat_features=X_train.select_dtypes(include=object).columns)\n",
    "#                         else:\n",
    "                        est = estimator.set_params(**diz_params)\n",
    "                        est.fit(X_train, ytrain)\n",
    "\n",
    "                        pred_train = est.predict_proba(X_train)\n",
    "                        pred_test = est.predict_proba(X_test)\n",
    "\n",
    "                        roc_train = float(round(roc_auc_score(ytrain, pred_train[:, 1]), 4))\n",
    "                        roc_test = float(round(roc_auc_score(ytest, pred_test[:, 1]), 4))\n",
    "                        print('\\n\\033[1mROC Train is {a}, ROC Test is {b}\\033[0m'.format(a=roc_train,\n",
    "                                                                                         b=roc_test))\n",
    "\n",
    "                        degree_overfitting = float((roc_train - roc_test) * 100)\n",
    "\n",
    "                        models[iteration] = {}\n",
    "\n",
    "                        if print_model == True:\n",
    "                                print(est)\n",
    "\n",
    "                        models[iteration]['diz_params'] = diz_params\n",
    "                        models[iteration]['degree_overfitting(%)'] = degree_overfitting\n",
    "                        models[iteration]['Train_AUC']= roc_train\n",
    "                        models[iteration]['Test_AUC']= roc_test\n",
    "                        # models[iteration]['est']= est\n",
    "\n",
    "                        iteration += 1\n",
    "                        del est\n",
    "\n",
    "        models = pd.DataFrame(models).T\n",
    "\n",
    "        for col in models.columns:\n",
    "                try:\n",
    "                        models[col] = models[col].astype(float)\n",
    "                except:\n",
    "                        pass\n",
    "\n",
    "        print('execution time (min)=', round((time.time() - temp) / 60, 1), ' finished at ', datetime.today())\n",
    "        return models.sort_values(by='Test_AUC', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hadoop/dsp-non-addressable-model'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### 200k for now out of hte 800k, we can fire up a larger instance or implement chunk loading in the future\n",
    "\n",
    "df = \\\n",
    "  pd.read_csv(\"~/train_data.csv\", \n",
    "              nrows=200000, \n",
    "              na_values=['-99', '\\\\N', '\\\\\\\\N',\n",
    "                         'Missing', 'missing', 'NA',\n",
    "                          '?', '.', 'NULL', '', ' '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bootstrap_script.sh',\n",
       " 'create_cluster.sh',\n",
       " 'create_modeling_cluster.sh',\n",
       " 'download_data.sh',\n",
       " 'download_modeling_data.sh',\n",
       " 'download_raw_clientfile.sh',\n",
       " 'limits.conf',\n",
       " 'md5_match_sample.csv',\n",
       " 'non_md5match_sample.csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!ls ./setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hadoop/dsp-non-addressable-model'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (3777,3783,3784,3786,3787,3788,3790,3875,3879,3885) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = \\\n",
    "  pd.read_csv(\"./setup/md5_match_sample.csv\", \n",
    "              nrows=200000, \n",
    "              na_values=['-99', '\\\\N', '\\\\\\\\N',\n",
    "                         'Missing', 'missing', 'NA',\n",
    "                          '?', '.', 'NULL', '', ' '])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Preprocessing Code\n",
    "- While we should update this later to create a stronger dataset, I did the following to filter out continous variables and get us a binary dataset. Additinoally, I remove all md5 features \n",
    "    - strip cols of \"'' \n",
    "    - remove explicit identifier columns\n",
    "    - extract binary features\n",
    "        - to mitigate issues with null vals/continuous variables i simply check that the value in the df == 1\n",
    "    - drop all zero columns\n",
    "        - this also will make sure all of our features are binary\n",
    "    - **remove md5 features**\n",
    "        - for a fraction of records we will make the md5 features null\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, null_frac=.7):\n",
    "    return \\\n",
    "      df.pipe(strip_cols) \\\n",
    "        .pipe(drop_unnecessary_cols) \\\n",
    "        .pipe(naive_extract_binary_features) \\\n",
    "        .pipe(drop_all_zero_cols) \\\n",
    "        .pipe(shuffle) \\\n",
    "        .astype(np.float32)\n",
    "        #.pipe(remove_md5_features, frac=null_frac) \\ we are not removing them now\n",
    "        #.pipe(shuffle) \\\n",
    "        \n",
    "def strip_cols(df):\n",
    "    df.columns = [x.replace(\"'\", \"\") for x in df.columns]\n",
    "    return df\n",
    "\n",
    "def drop_unnecessary_cols(df):\n",
    "    cols_to_drop = ['RFI', 'PROFILE_ID', 'PASZIPCODE','SHA_256','EMAIL_MD5','TU_MATCH_FLAG']\n",
    "    return df.drop(columns=cols_to_drop)\n",
    "\n",
    "def naive_extract_binary_features(df):\n",
    "    return (df == 1).astype(int)\n",
    "\n",
    "def drop_all_zero_cols(df):\n",
    "    cols_with_all_zeros = \\\n",
    "      (df.sum() == 0).loc[lambda x: x == True] \\\n",
    "      .index\n",
    "    return df.drop(columns=cols_with_all_zeros)\n",
    "\n",
    "def shuffle(df):\n",
    "    return df.sample(frac=1) \\\n",
    "             .reset_index(drop=True)\n",
    "\n",
    "def remove_md5_features(df, frac=.7):\n",
    "    \"\"\"for a fraction of the records, we make all the md5 features 0\"\"\"\n",
    "    x_columns = [x for x in df.columns if x != 'label']\n",
    "    \n",
    "    non_md5_features = [x for x in x_columns if not re.match(\"\\d{1,}\", x)]\n",
    "    null_records = int(len(df) * frac)\n",
    "    now_null_df = df.iloc[:null_records] \\\n",
    "                    .assign(**{ftr: 0 for ftr in non_md5_features})\n",
    "    return \\\n",
    "     pd.concat([now_null_df, df.iloc[null_records:]], axis='rows')\n",
    "\n",
    "\n",
    "#compare to standard logistic regression on this set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Pytorch Dataset\n",
    "- Pytorch dataset requires you to implement \n",
    "    - `__len__` length of dataset\n",
    "    - `__getitem_` iterator of how to get the next row in a dataset\n",
    "    \n",
    "    \n",
    "- Here we create two different kinds of datasets\n",
    "    - `NonAddressableLRDataset`\n",
    "        - This dataset does not contain the label, which we will then use to run a logistic regression on the latent features\n",
    "    - `NonAddressableImputationDataset`\n",
    "        - This dataset does contain the label, and we will make our predictions via reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonAddressableLRDataset(Dataset):\n",
    "    \"\"\"Pytorch Dataset WITHOUT LABEL\"\"\"\n",
    "    def __init__(self, df, transform=None):\n",
    "        df = df.reset_index(drop=True)\n",
    "        self.X = df[[x for x in df.columns if x != 'label']]\n",
    "        self.Y = df['label']\n",
    "        self.transform = transform\n",
    "        self.VISIBLE_UNITS = len(self.X.columns)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist() \n",
    "        features = torch.tensor(self.X.iloc[idx].values)\n",
    "        label = torch.tensor(self.Y.iloc[[idx]].values)\n",
    "        if self.transform is not None:\n",
    "            features = self.transform(features)\n",
    "        return features, label\n",
    "    \n",
    "class NonAddressableImputationDataset(Dataset):\n",
    "    \"\"\"The same as the previous class, however, we have label\"\"\"   \n",
    "    def __init__(self, df, transform=None):\n",
    "        df = df.reset_index(drop=True)\n",
    "        self.X = df\n",
    "        self.transform = transform\n",
    "        self.VISIBLE_UNITS = len(self.X.columns)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist() \n",
    "        features = torch.tensor(self.X.iloc[idx].values)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            features = self.transform(features)\n",
    "            \n",
    "        return features\n",
    "    \n",
    "def plot_loss(losses):\n",
    "    pd.DataFrame(losses, columns=['epoch', 'loss']) \\\n",
    "      .set_index(\"epoch\") \\\n",
    "      .plot(kind='line')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Functions for LR RBM\n",
    "- Here we are training RBM and then running a logistic regression on the latent features so we do not use the label in our training\n",
    "\n",
    "`train_lr_RBM`\n",
    "- Trains RBM in the case that we are excluding the label\n",
    "\n",
    "`generate_latent_features`\n",
    "- Performs a forward pass on our train/test data and returns the latent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lr_RBM(train_loader,\n",
    "                 VISIBLE_UNITS,\n",
    "                 BATCH_SIZE=64,\n",
    "                 HIDDEN_UNITS=128, \n",
    "                 CD_K=1, \n",
    "                 EPOCHS=60,\n",
    "                 use_cuda=False):\n",
    "    rbm = RBM(VISIBLE_UNITS, HIDDEN_UNITS, CD_K, use_cuda=CUDA)\n",
    "    loss = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        epoch_error = 0.0\n",
    "    \n",
    "        for batch, _ in train_loader:\n",
    "            batch = batch.view(len(batch), VISIBLE_UNITS)  # flatten input data\n",
    "    \n",
    "            if CUDA:\n",
    "                batch = batch.cuda()\n",
    "    \n",
    "            batch_error = rbm.contrastive_divergence(batch)\n",
    "    \n",
    "            epoch_error += batch_error\n",
    "    \n",
    "        print('Epoch Error (epoch=%d): %.4f' % (epoch, epoch_error))\n",
    "        loss.append([epoch, epoch_error.item()])\n",
    "    return rbm, loss\n",
    "    \n",
    "def generate_latent_features(rbm,\n",
    "                             train_dataset,\n",
    "                             test_dataset,\n",
    "                             train_loader,\n",
    "                             test_loader,\n",
    "                             HIDDEN_UNITS=128):\n",
    "    VISIBLE_UNITS = train_dataset.VISIBLE_UNITS\n",
    "    train_features = np.zeros((len(train_dataset), HIDDEN_UNITS))\n",
    "    train_labels = np.zeros(len(train_dataset))\n",
    "    test_features = np.zeros((len(test_dataset), HIDDEN_UNITS))\n",
    "    test_labels = np.zeros(len(test_dataset))\n",
    "    \n",
    "    for i, (batch, labels) in enumerate(train_loader):\n",
    "        batch = batch.view(len(batch), VISIBLE_UNITS)  # flatten input data\n",
    "    \n",
    "        if CUDA:\n",
    "            batch = batch.cuda()\n",
    "    \n",
    "        train_features[i*BATCH_SIZE:i*BATCH_SIZE+len(batch)] = rbm.sample_hidden(batch).cpu().numpy()\n",
    "        train_labels[i*BATCH_SIZE:i*BATCH_SIZE+len(batch)] = labels.numpy().flatten()\n",
    "    \n",
    "    for i, (batch, labels) in enumerate(test_loader):\n",
    "        batch = batch.view(len(batch), VISIBLE_UNITS)  # flatten input data\n",
    "    \n",
    "        if CUDA:\n",
    "            batch = batch.cuda()\n",
    "    \n",
    "        test_features[i*BATCH_SIZE:i*BATCH_SIZE+len(batch)] = rbm.sample_hidden(batch).cpu().numpy()\n",
    "        test_labels[i*BATCH_SIZE:i*BATCH_SIZE+len(batch)] = labels.numpy().flatten()\n",
    "    \n",
    "    return train_features, train_labels, test_features, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_DF = \\\n",
    "  df.pipe(preprocess).astype(np.float32)\n",
    "X = list([x for x in preprocessed_DF.columns if x != \"label\"])\n",
    "Y = \"label\"\n",
    "md5_features = [x for x in preprocessed_DF.columns if re.match(\"\\d{1,}\", x)]\n",
    "non_md5_features = [x for x in preprocessed_DF.columns if not re.match(\"\\d{1,}\", x) and x != \"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61841"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training RBM for the LR case\n",
    "- I did not tune hyperparameters yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Error (epoch=0): 30298506.0000\n",
      "Epoch Error (epoch=1): 14565626.0000\n",
      "Epoch Error (epoch=2): 13893167.0000\n",
      "Epoch Error (epoch=3): 13474336.0000\n",
      "Epoch Error (epoch=4): 13186837.0000\n",
      "Epoch Error (epoch=5): 12980025.0000\n",
      "Epoch Error (epoch=6): 12845203.0000\n",
      "Epoch Error (epoch=7): 12734334.0000\n",
      "Epoch Error (epoch=8): 12646727.0000\n",
      "Epoch Error (epoch=9): 12573965.0000\n",
      "Epoch Error (epoch=10): 12514105.0000\n",
      "Epoch Error (epoch=11): 12452686.0000\n",
      "Epoch Error (epoch=12): 12396238.0000\n",
      "Epoch Error (epoch=13): 12343818.0000\n",
      "Epoch Error (epoch=14): 12291966.0000\n",
      "Epoch Error (epoch=15): 12248524.0000\n",
      "Epoch Error (epoch=16): 12210264.0000\n",
      "Epoch Error (epoch=17): 12174630.0000\n",
      "Epoch Error (epoch=18): 12142232.0000\n",
      "Epoch Error (epoch=19): 12114341.0000\n",
      "Epoch Error (epoch=20): 12085878.0000\n",
      "Epoch Error (epoch=21): 12063129.0000\n",
      "Epoch Error (epoch=22): 12041521.0000\n",
      "Epoch Error (epoch=23): 12022449.0000\n",
      "Epoch Error (epoch=24): 12003616.0000\n",
      "Epoch Error (epoch=25): 11987260.0000\n",
      "Epoch Error (epoch=26): 11973411.0000\n",
      "Epoch Error (epoch=27): 11958940.0000\n",
      "Epoch Error (epoch=28): 11947713.0000\n",
      "Epoch Error (epoch=29): 11937500.0000\n",
      "Epoch Error (epoch=30): 11927401.0000\n",
      "Epoch Error (epoch=31): 11918059.0000\n",
      "Epoch Error (epoch=32): 11909280.0000\n",
      "Epoch Error (epoch=33): 11901916.0000\n",
      "Epoch Error (epoch=34): 11894900.0000\n",
      "Epoch Error (epoch=35): 11888875.0000\n",
      "Epoch Error (epoch=36): 11881344.0000\n",
      "Epoch Error (epoch=37): 11877091.0000\n",
      "Epoch Error (epoch=38): 11872043.0000\n",
      "Epoch Error (epoch=39): 11869270.0000\n",
      "Epoch Error (epoch=40): 11866246.0000\n",
      "Epoch Error (epoch=41): 11862569.0000\n",
      "Epoch Error (epoch=42): 11859797.0000\n",
      "Epoch Error (epoch=43): 11854056.0000\n",
      "Epoch Error (epoch=44): 11850305.0000\n",
      "Epoch Error (epoch=45): 11848194.0000\n",
      "Epoch Error (epoch=46): 11844126.0000\n",
      "Epoch Error (epoch=47): 11840638.0000\n",
      "Epoch Error (epoch=48): 11837127.0000\n",
      "Epoch Error (epoch=49): 11835116.0000\n",
      "Epoch Error (epoch=50): 11831702.0000\n",
      "Epoch Error (epoch=51): 11827636.0000\n",
      "Epoch Error (epoch=52): 11824962.0000\n",
      "Epoch Error (epoch=53): 11821290.0000\n",
      "Epoch Error (epoch=54): 11818034.0000\n",
      "Epoch Error (epoch=55): 11815099.0000\n",
      "Epoch Error (epoch=56): 11811379.0000\n",
      "Epoch Error (epoch=57): 11807566.0000\n",
      "Epoch Error (epoch=58): 11804888.0000\n",
      "Epoch Error (epoch=59): 11800492.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAERCAYAAAB1k2wJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAhSUlEQVR4nO3dfZRcdZ3n8fenHro7SXceIE3APBAQVBBJ0BBFMIDuIHh0WVZmhGURGZwcPYyjO6wzors643rOnJEdGGfUYXKGCOwCggrK+gBkkENAFOjEREIiEHmQjoE8P5Cn7q767h/3VqfS6U5Xd1fS3bc/r3PqVN3f/d1bvx9UPvf2r351ryICMzPLrtxwN8DMzA4vB72ZWcY56M3MMs5Bb2aWcQ56M7OMc9CbmWXciA16SYslbZC0qoa6N0lakT6el7TtCDTRzGxU0EidRy9pAfAGcHtEnDaA7T4DnBERf3rYGmdmNoqM2DP6iFgKbKkuk/RmSQ9IWibpMUlv62XTy4G7jkgjzcxGgcJwN2CAFgGfiogXJL0b+Dbw/spKSccDJwA/H6b2mZmNOKMm6CU1A+8FviepUtzYo9plwPcjonQk22ZmNpKNmqAnGWbaFhFzD1HnMuDaI9McM7PRYcSO0fcUETuAlyT9MYAScyrr0/H6KcAvh6mJZmYj0ogNekl3kYT2WyW1S7oGuAK4RtJK4Fng4qpNLgO+GyN1GpGZ2TAZsdMrzcysPkbsGb2ZmdXHiPwydurUqTF79uzhboaZ2aixbNmyTRHR2tu6ERn0s2fPpq2tbbibYWY2akh6pa91HroxM8s4B72ZWcY56M3MMm5EjtGbmQ1VZ2cn7e3t7N27d7ibUldNTU3MmDGDYrFY8zYOejPLpPb2dlpaWpg9ezZV18ca1SKCzZs3097ezgknnFDzdh66MbNM2rt3L0cffXRmQh5AEkcfffSA/0px0JtZZmUp5CsG06dMBf0/PfwCjz6/cbibYWY2ovQb9JKaJD0laaWkZyX9bS91GiXdLWmtpCclza5ad31a/pykD9a5/Qe4+dHf8ZiD3sxGiObm5uFuAlDbGf0+4P0RMQeYC1wo6T096lwDbI2Ik4CbgL8HkHQqyVUl3w5cCHxbUr5ObT9IYyFHR6l8uHZvZjYq9Rv0kXgjXSymj56XvLwYuC19/X3gA0oGki4muXTwvoh4CVgLzK9Ly3vRWMizr9NBb2YjS0Tw+c9/ntNOO413vOMd3H333QCsX7+eBQsWMHfuXE477TQee+wxSqUSn/jEJ7rr3nTTTUN+/5qmV6Zn4cuAk4BvRcSTPapMB15NO9QlaTtwdFr+q6p67WlZb++xEFgIMGvWrAF0Yb/GYo59Xb6LoJkd6G//37Os/sOOuu7z1DdN5CsfeXtNde+9915WrFjBypUr2bRpE2eeeSYLFizgzjvv5IMf/CBf+tKXKJVK7N69mxUrVrBu3TpWrVoFwLZt24bc1pq+jI2IUnoLvxnAfEmnDfmdD36PRRExLyLmtbb2egG2fjUWcuzr8hm9mY0sjz/+OJdffjn5fJ5p06Zx7rnn8vTTT3PmmWfyne98h7/5m7/hmWeeoaWlhRNPPJEXX3yRz3zmMzzwwANMnDhxyO8/oB9MRcQ2SY+QjLevqlq1DpgJtEsqAJOAzVXlFTPSssOiwUFvZr2o9cz7SFuwYAFLly7lJz/5CZ/4xCf4y7/8Sz7+8Y+zcuVKHnzwQW6++WbuueceFi9ePKT3qWXWTaukyenrccAfAb/tUe1+4Kr09aXAz9Nb+t0PXJbOyjkBOBl4akgtPoTGQt5DN2Y24rzvfe/j7rvvplQqsXHjRpYuXcr8+fN55ZVXmDZtGn/2Z3/GJz/5SZYvX86mTZsol8t89KMf5Wtf+xrLly8f8vvXckZ/HHBbOk6fA+6JiB9L+irQFhH3A7cA/0fSWmALyUwbIuJZSfcAq4Eu4NqIOGxJ3FjI+ctYMxtxLrnkEn75y18yZ84cJPH1r3+dY489lttuu40bbriBYrFIc3Mzt99+O+vWrePqq6+mXE6y7O/+7u+G/P4j8p6x8+bNi8HceOTq7zzF5l0d3P/n5xyGVpnZaLJmzRpOOeWU4W7GYdFb3yQti4h5vdXP1C9jPb3SzOxg2Qp6T680MztItoLes27MrMpIHJoeqsH0KVNB7+mVZlbR1NTE5s2bMxX2levRNzU1DWi7TN14JBmj99CNmcGMGTNob29n48ZsXeiwcoepgchY0PuM3swSxWJxQHdhyrJMDd00FvJ0lYNSOTt/qpmZDVW2gr6YdKfDZ/VmZt2yFfSFpDueYmlmtl/Ggj65p4nH6c3M9stU0DdUzuj961gzs26ZCnoP3ZiZHSyjQe8zejOzimwFfdFj9GZmPWUr6D10Y2Z2kIwGvc/ozcwqMhb06dCNZ92YmXXLVNA3eOjGzOwg/V7UTNJM4HZgGhDAooj4Ro86nweuqNrnKUBrRGyR9DKwEygBXX3d6qoePHRjZnawWq5e2QVcFxHLJbUAyyQtiYjVlQoRcQNwA4CkjwD/LSK2VO3j/IjYVM+G96ZyrRsHvZnZfv0O3UTE+ohYnr7eCawBph9ik8uBu+rTvIGpjNH7omZmZvsNaIxe0mzgDODJPtaPBy4EflBVHMBDkpZJWniIfS+U1CapbbA3CvD0SjOzg9Uc9JKaSQL8cxGxo49qHwF+0WPY5pyIeCdwEXCtpAW9bRgRiyJiXkTMa21trbVZB2j0tW7MzA5SU9BLKpKE/B0Rce8hql5Gj2GbiFiXPm8A7gPmD66pNbXT9401M+uh36CXJOAWYE1E3HiIepOAc4EfVZVNSL/ARdIE4AJg1VAbfSiN+ZyHbszMqtQy6+Zs4ErgGUkr0rIvArMAIuLmtOwS4KGI2FW17TTgvuRYQQG4MyIeqEO7+9RY9Bm9mVm1foM+Ih4HVEO9W4Fbe5S9CMwZZNsGpbGQ9xi9mVmVTP0yFpIvZDtKDnozs4rMBX1DIce+To/Rm5lVZC7oG4t5j9GbmVXJXtAXPOvGzKxaRoPeZ/RmZhXZDHrPujEz65bBoM976MbMrEoGg97TK83MqmUv6IseujEzq5a9oC94eqWZWbUMBr2nV5qZVctc0FcuUxwRw90UM7MRIXNB31jIEQGdJQe9mRlkMuiT+8Z6+MbMLJG9oC8mXfINws3MEtkL+u4bhDvozcwgk0FfGbpx0JuZQSaDvnJG7zF6MzOo7ebgMyU9Imm1pGclfbaXOudJ2i5pRfr4ctW6CyU9J2mtpC/UuwM9NVSC3r+ONTMDars5eBdwXUQsl9QCLJO0JCJW96j3WER8uLpAUh74FvBHQDvwtKT7e9m2bjx0Y2Z2oH7P6CNifUQsT1/vBNYA02vc/3xgbUS8GBEdwHeBiwfb2FpUZt146MbMLDGgMXpJs4EzgCd7WX2WpJWSfibp7WnZdODVqjrt9HGQkLRQUpukto0bNw6kWQeojNF7eqWZWaLmoJfUDPwA+FxE7OixejlwfETMAf4Z+OFAGxIRiyJiXkTMa21tHejm3Tx0Y2Z2oJqCXlKRJOTviIh7e66PiB0R8Ub6+qdAUdJUYB0ws6rqjLTssPGsGzOzA9Uy60bALcCaiLixjzrHpvWQND/d72bgaeBkSSdIagAuA+6vV+N70z1G71k3ZmZAbbNuzgauBJ6RtCIt+yIwCyAibgYuBT4tqQvYA1wWyeUjuyT9OfAgkAcWR8Sz9e3CgRry/mWsmVm1foM+Ih4H1E+dbwLf7GPdT4GfDqp1g9BY9EXNzMyqZfeXsR66MTMDMhj0hZzICd8g3Mwslbmgl+T7xpqZVclc0EMy82Zfp8fozcwgq0Gf3jfWzMwyG/QeujEzq8hk0DcUcp5eaWaWymTQNxZynl5pZpbKbNB7eqWZWSKjQZ/3Gb2ZWSqbQV/0GL2ZWUU2g97TK83MumU06D290sysIpNB31DwL2PNzCoyGfQeujEz2y+jQZ/3zcHNzFLZDPqiz+jNzCpquWfsTEmPSFot6VlJn+2lzhWSfiPpGUlPSJpTte7ltHyFpLZ6d6A3lR9MlctxJN7OzGxEq+WesV3AdRGxXFILsEzSkohYXVXnJeDciNgq6SJgEfDuqvXnR8Sm+jX70BoLye0EO0plmnL5I/W2ZmYjUr9n9BGxPiKWp693AmuA6T3qPBERW9PFXwEz6t3QgfDtBM3M9hvQGL2k2cAZwJOHqHYN8LOq5QAekrRM0sIBt3AQGipB71/HmpnVNHQDgKRm4AfA5yJiRx91zicJ+nOqis+JiHWSjgGWSPptRCztZduFwEKAWbNmDaALB+s+o/cXsmZmtZ3RSyqShPwdEXFvH3VOB/4NuDgiNlfKI2Jd+rwBuA+Y39v2EbEoIuZFxLzW1taB9aKHxmIyLu+gNzOrbdaNgFuANRFxYx91ZgH3AldGxPNV5RPSL3CRNAG4AFhVj4YfSqOHbszMutUydHM2cCXwjKQVadkXgVkAEXEz8GXgaODbyXGBroiYB0wD7kvLCsCdEfFAPTvQGw/dmJnt12/QR8TjgPqp80ngk72UvwjMOXiLw6syvdKzbszMMvzLWPDQjZkZZDToG/IeujEzq8hk0DcVHfRmZhWZDPruSyA46M3Mshr0HqM3M6vIaNB71o2ZWUU2g95j9GZm3TIZ9Ptn3Xjoxswsk0Gfy4liXj6jNzMjo0EPyTi9x+jNzDId9Dk6Sh66MTPLdND7jN7MLMtBX8x7jN7MjCwHfSHnWTdmZmQ+6H1Gb2aW2aBv8Bi9mRmQ4aBvLOQ9dGNmRqaDPkdHyWf0Zma13Bx8pqRHJK2W9Kykz/ZSR5L+SdJaSb+R9M6qdVdJeiF9XFXvDvSlseihGzMzqO3m4F3AdRGxXFILsEzSkohYXVXnIuDk9PFu4F+Ad0s6CvgKMA+IdNv7I2JrXXvRi2ToxkFvZtbvGX1ErI+I5enrncAaYHqPahcDt0fiV8BkSccBHwSWRMSWNNyXABfWtQd98PRKM7PEgMboJc0GzgCe7LFqOvBq1XJ7WtZXeW/7XiipTVLbxo0bB9KsXnl6pZlZouagl9QM/AD4XETsqHdDImJRRMyLiHmtra1D3p+nV5qZJWoKeklFkpC/IyLu7aXKOmBm1fKMtKyv8sPO0yvNzBK1zLoRcAuwJiJu7KPa/cDH09k37wG2R8R64EHgAklTJE0BLkjLDrvGQo5yQJenWJrZGFfLrJuzgSuBZyStSMu+CMwCiIibgZ8CHwLWAruBq9N1WyT9L+DpdLuvRsSWurX+EKpvJ1jIZ/bnAmZm/eo36CPicUD91Ang2j7WLQYWD6p1Q9B9g/CuMhMaj/S7m5mNHJk91W0s+L6xZmaQ5aCvDN145o2ZjXGZDfqG/P6hGzOzsSyzQe+hGzOzRHaDPh266fAZvZmNcdkN+oKHbszMINNB76EbMzPIctB71o2ZGZDloPfQjZkZkOGgb/DQjZkZkOGg3z9G7zN6MxvbMh/0nl5pZmNdhoPeY/RmZpDhoC/mhQT7Oj1Gb2ZjW2aDXpLvG2tmRoaDHiq3E3TQm9nYlumgbyjkPL3SzMa8TAd9YyHnX8aa2ZjX760EJS0GPgxsiIjTeln/eeCKqv2dArSm94t9GdgJlICuiJhXr4bXorGQY59vDm5mY1wtZ/S3Ahf2tTIiboiIuRExF7geeLTHDcDPT9cf0ZCHdIzeZ/RmNsb1G/QRsRTY0l+91OXAXUNqUR01Fj1Gb2ZWtzF6SeNJzvx/UFUcwEOSlkla2M/2CyW1SWrbuHFjXdrk6ZVmZvX9MvYjwC96DNucExHvBC4CrpW0oK+NI2JRRMyLiHmtra11aZCnV5qZ1TfoL6PHsE1ErEufNwD3AfPr+H79aijk/MtYMxvz6hL0kiYB5wI/qiqbIKml8hq4AFhVj/erVWMh54uamdmYV8v0yruA84CpktqBrwBFgIi4Oa12CfBQROyq2nQacJ+kyvvcGREP1K/p/fPQjZlZDUEfEZfXUOdWkmmY1WUvAnMG27B6SGbdOOjNbGzL/i9jPb3SzMa4jAe9h27MzDIe9MmXsREx3E0xMxs2mQ76Bt831sws20HvG4SbmWU96IvJfWM9l97MxrJsB333Gb1n3pjZ2DVGgt5n9GY2dmU86JOhG1+T3szGsmwHfdFDN2Zm2Q76vIduzMyyHfRFB72ZWbaDvuDplWZmGQ96j9GbmWU86D3rxsws20HvMXozs4wHvYduzMyyHfS+eqWZWQ1BL2mxpA2Ser2xt6TzJG2XtCJ9fLlq3YWSnpO0VtIX6tnwWjRU5tF7jN7MxrBazuhvBS7sp85jETE3fXwVQFIe+BZwEXAqcLmkU4fS2IEq5HMUcqKj5KEbMxu7+g36iFgKbBnEvucDayPixYjoAL4LXDyI/QxJYyHnM3ozG9PqNUZ/lqSVkn4m6e1p2XTg1ao67WlZryQtlNQmqW3jxo11alZyTXqP0ZvZWFaPoF8OHB8Rc4B/Bn44mJ1ExKKImBcR81pbW+vQrERjIedZN2Y2pg056CNiR0S8kb7+KVCUNBVYB8ysqjojLTuikqD3Gb2ZjV1DDnpJx0pS+np+us/NwNPAyZJOkNQAXAbcP9T3G6gGj9Gb2RhX6K+CpLuA84CpktqBrwBFgIi4GbgU+LSkLmAPcFlEBNAl6c+BB4E8sDginj0svTiEY1qaWPb7rWzZ1cFRExqO9NubmQ07JZk8ssybNy/a2trqsq9V67bzn7/9BOe+tZVFV76L9I8PM7NMkbQsIub1ti7Tv4wFOG36JP7qwreyZPXr3PHk74e7OWZmR1zmgx7gT88+gfedPJWv/WQ1L7y+c7ibY2Z2RI2JoM/lxD/8yRwmNBT4i++uYG+np1ua2dgxJoIeki9lb/jj01mzfgdff+C54W6OmdkRM2aCHuD9b5vGVWcdz+JfvMQjz20Y7uaYmR0RYyroAa7/0Cm8dVoLf3Hnr/nF2k3D3Rwzs8NuzAV9UzHP4qvP5LjJTVy1+Cm+v6x9uJtkZnZYjbmgB5g+eRzf+9R7mX/CUfz3763kpiXPMxJ/T2BmVg9jMugBJo0rcuvV87n0XTP4xsMvcN09K+nwNXHMLIP6vQRCljUUctxw6enMOmo8Ny55nvZte/j6R09n9tQJw900M7O6GbNn9BWS+IsPnMxNH5vD6j/s4IKblvK/H3yO3R1dw900M7O6GPNBX3HJGTP4+XXn8uHTj+Obj6zlP/zDo/zsmfUeuzezUc9BX+WYiU3c+LG5fO9TZzFxXJFP37GcK295iid+t8mBb2ajVuavXjlYXaUydzz5e/7x359n6+5O3jqthY+/93guOWM64xvG9FcbZjYCHerqlQ76fuztLHH/yj9w2xMv8+wfdjCxqcDHzpzJh95xHKfPmEw+58sem9nwc9DXQUTQ9spWbn3iZR5Y9RqlcjB5fJFzTprKgre0cu5bWpk2sWm4m2lmY9Shgt5jEDWSxJmzj+LM2UexZVcHj6/dxKPPbWTpCxv58W/WA3Di1Am86/gpzJs9hXcdP4U3tzb7RidmNuz6PaOXtBj4MLAhIk7rZf0VwF8DAnYCn46Ilem6l9OyEtDV19Gmp5F4Rt+XiGDN+p0sfWEjbS9vYdkrW9m6uxOAyeOLnD5jMqcc28Ipx03kbce18ObWZop5fwduZvU11DP6W4FvArf3sf4l4NyI2CrpImAR8O6q9edHRGavHiaJU980kVPfNBHOfTMRwe827mL5K1tpe2ULq9bt4Du/20xHKfnVbTEvTpzazImtEzhh6gRObG3mhKnJ6ynji/4LwMzqrt+gj4ilkmYfYv0TVYu/AmbUoV2jliROOqaZk45p5k/OnAlAZ6nMS5t2sWb9Dlav38HvNrzBc6/tZMnq1+kq7/+LakJDnhlTxjNjyjimTxnHjCnjmDllPDOmjGfmUeOYNM4HAjMbuHqP0V8D/KxqOYCHJAXwrxGxqK8NJS0EFgLMmjWrzs0aXsV8jrdMa+Et01q4eO707vLOUplXt+zmxY27eHnzLtZt20P71uTx1Mtb2Ln3wF/ntjQWmD5lHNMnj+NN3Y8mpk8ex7GTmpg2scnDQmZ2kLoFvaTzSYL+nKricyJinaRjgCWSfhsRS3vbPj0ILIJkjL5e7RrJivkcJ7Y2c2Jrc6/rt+/ppH3rbl7dsof2rbtp37qHV7fs5g/b99L2yla27+k8oL4EU5sbOS4N/ernYyc2dR8MJjT6O3izsaQu/+IlnQ78G3BRRGyulEfEuvR5g6T7gPlAr0FvB5s0rsikcZN4+5sm9br+jX1drN+2h/Zte3h9+17Wb9/La9v38tqOvbyyeRdPvriZHXsPvmbPuGKeqS0NTG1uTB8NHDWhgSnj0+cJDRw1PlmePKFIS2PBQ0Zmo9iQg17SLOBe4MqIeL6qfAKQi4id6esLgK8O9f1sv+bGAidPa+HkaS191tnd0dUd/q9t38uGnfvYtHMfm97Yx6Y3Onh1y25+/fttbN3dQanc+x9ShZyYPL7I5PEN6cGnyORxRSamr1uaCkxsKtLcVKClqUBLUzF9TsobCzkfKMyGUb9BL+ku4DxgqqR24CtAESAibga+DBwNfDv9x1yZRjkNuC8tKwB3RsQDh6EPdgjjGwqHHB6qiAh27O1iy64OtuzqYOuuDrbu7mDb7k627u5g6+5Otu3uYPueTl7fsZfnX9/J9j2dB32P0JtiXrQ0FWluLDC+Ic+ExkLyaMgzriHPhIakvPJ6XEM+WS7maUqfu5fTx7h02b9MNuuffxlrQ1IqB2/s62Ln3iT0k0dn9/OOtGzH3k527+tiV0eJ3R1d7Np34PPujhL7BnHjl2JeNBbyNBVz3c8NhTyNhRwNhRyN3Y9893L1czGfPBryOYp5USzkKOZyFPJK1yXPhXyOYk7Jc3eZKOSS5er1+ZySslyOQk7kfDCyI8C/jLXDJp9T93DOUHWVyuzpLLG7o8TezhJ7Okvs6dj/vLezzO6Orqp1ZfZ2JXX3dZWT584y+7rK7Osq0dFV5o19XWzZVaaja3/5vq79y30NV9VTTlDIJQeAyqNQ9bqynMuJvA4sr65bvY+cRE6QS+ur6nXynCxLlXUgkm32lwkBuartK/tUZV319lXb5ZW0t9LuXNX2krr3LaUPqt+jul5altu/3f427G9zLle9v8rrA9t4qP1X/vKr7KeWbdRbO7q3G10Hbwe9jRiFfI6WfI6WpqEfNGpVLged5TKdpaCzq0xHqUxnqUxXKegspeWlMl1pna5SWr+rTFc5uuvuX5+Ud5WT152loBzJcqmcbF8qJ3XKkS5Huq4clKueK+WVdXs6S+l+ypTLUI5IH0k/ypFsU1lXKifrIIigu25EEFBVltbruWyHpIMObvsPGgcfOA8+MFUOcNXbTJ3QyD2fOqvubXXQ25iWy4nGXJ7GAtA43K0ZWSL2HyCC9DmqDiJl6CqXKUWkB4mqA0UZIj3ARLqvykGnu17VwarngahU3v+e1fuOqnZ1779qWwhK6XtX76uyP3r0p5we8cpV+yiXo2r7Sr8rbTy4HX21u/q/VeXAWtmmVOlD1YG1FMHEpsMTyQ56M+tV91ANo2uYwg7mn1GamWWcg97MLOMc9GZmGeegNzPLOAe9mVnGOejNzDLOQW9mlnEOejOzjBuRFzWTtBF4ZZCbTwWyco/aLPUF3J+RLEt9gWz1p9a+HB8Rrb2tGJFBPxSS2vq6gttok6W+gPszkmWpL5Ct/tSjLx66MTPLOAe9mVnGZTHoFw13A+ooS30B92cky1JfIFv9GXJfMjdGb2ZmB8riGb2ZmVVx0JuZZVxmgl7ShZKek7RW0heGuz0DJWmxpA2SVlWVHSVpiaQX0ucpw9nGWkmaKekRSaslPSvps2n5aO1Pk6SnJK1M+/O3afkJkp5MP3N3S2oY7rbWSlJe0q8l/ThdHs19eVnSM5JWSGpLy0blZw1A0mRJ35f0W0lrJJ011P5kIugl5YFvARcBpwKXSzp1eFs1YLcCF/Yo+wLwcEScDDycLo8GXcB1EXEq8B7g2vT/x2jtzz7g/RExB5gLXCjpPcDfAzdFxEnAVuCa4WvigH0WWFO1PJr7AnB+RMytmm8+Wj9rAN8AHoiItwFzSP4/Da0/0X0/xNH7AM4CHqxavh64frjbNYh+zAZWVS0/BxyXvj4OeG642zjIfv0I+KMs9AcYDywH3k3ya8VCWn7AZ3AkP4AZaVi8H/gxoNHal7S9LwNTe5SNys8aMAl4iXSiTL36k4kzemA68GrVcntaNtpNi4j16evXgGnD2ZjBkDQbOAN4klHcn3SoYwWwAVgC/A7YFhFdaZXR9Jn7R+CvgHK6fDSjty+Q3H/8IUnLJC1My0brZ+0EYCPwnXRo7d8kTWCI/clK0GdeJIfyUTUXVlIz8APgcxGxo3rdaOtPRJQiYi7J2fB84G3D26LBkfRhYENELBvuttTRORHxTpKh22slLaheOco+awXgncC/RMQZwC56DNMMpj9ZCfp1wMyq5Rlp2Wj3uqTjANLnDcPcnppJKpKE/B0RcW9aPGr7UxER24BHSIY3JksqpKtGy2fubOA/SnoZ+C7J8M03GJ19ASAi1qXPG4D7SA7Eo/Wz1g60R8ST6fL3SYJ/SP3JStA/DZyczhxoAC4D7h/mNtXD/cBV6eurSMa6RzxJAm4B1kTEjVWrRmt/WiVNTl+PI/m+YQ1J4F+aVhsV/YmI6yNiRkTMJvl38vOIuIJR2BcASRMktVReAxcAqxiln7WIeA14VdJb06IPAKsZan+G+8uHOn6J8SHgeZKx0y8Nd3sG0f67gPVAJ8lR/RqSsdOHgReAfweOGu521tiXc0j+tPwNsCJ9fGgU9+d04Ndpf1YBX07LTwSeAtYC3wMah7utA+zXecCPR3Nf0navTB/PVv7tj9bPWtr2uUBb+nn7ITBlqP3xJRDMzDIuK0M3ZmbWBwe9mVnGOejNzDLOQW9mlnEOejOzjHPQm9WRpPMqV4Q0Gykc9GZmGeegtzFJ0n9NrzG/QtK/phcte0PSTek15x+W1JrWnSvpV5J+I+m+yrXAJZ0k6d/T69Qvl/TmdPfNVdcTvyP9pbDZsHHQ25gj6RTgY8DZkVyorARcAUwA2iLi7cCjwFfSTW4H/joiTgeeqSq/A/hWJNepfy/JL5shuVrn50jujXAiyfVlzIZNof8qZpnzAeBdwNPpyfY4kotElYG70zr/F7hX0iRgckQ8mpbfBnwvvb7K9Ii4DyAi9gKk+3sqItrT5RUk9xl4/LD3yqwPDnobiwTcFhHXH1Ao/c8e9QZ7fZB9Va9L+N+ZDTMP3dhY9DBwqaRjoPv+oseT/HuoXMHxvwCPR8R2YKuk96XlVwKPRsROoF3Sf0r30Shp/JHshFmtfKZhY05ErJb0P0juSpQjuWLotSQ3eZifrttAMo4PyWVhb06D/EXg6rT8SuBfJX013ccfH8FumNXMV680S0l6IyKah7sdZvXmoRszs4zzGb2ZWcb5jN7MLOMc9GZmGeegNzPLOAe9mVnGOejNzDLu/wNMvqCqncG7pQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "HIDDEN_UNITS = 128\n",
    "CD_K = 1\n",
    "EPOCHS = 60\n",
    "CUDA = False\n",
    "\n",
    "train, test = train_test_split(preprocessed_DF, test_size=.4)\n",
    "\n",
    "train_dataset = NonAddressableLRDataset(train)\n",
    "test_dataset = NonAddressableLRDataset(test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader= torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "rbm, losses = train_lr_RBM(train_loader, \n",
    "                           train_dataset.VISIBLE_UNITS, EPOCHS = EPOCHS , CD_K = CD_K, use_cuda = CUDA)\n",
    "plot_loss(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels, test_features, test_labels = \\\n",
    "  generate_latent_features(rbm,\n",
    "                           train_dataset,\n",
    "                           test_dataset,\n",
    "                           train_loader,\n",
    "                           test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary Evaluation for the LR case\n",
    "- In order to get an idea of the performance w/ this data \n",
    "    - a classifier w the latent features from the RBM\n",
    "    - a classifier on the raw training features \n",
    " \n",
    "#### Notes\n",
    "- I believe LogisticRegression in sklearn defaults doing L2 penalty, so perhaps the delta in results between the two is due to l2 being better suited for the lower dimensional latent // continous feautres than the high dimensional sparse matrix that we started with\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.910194e-01</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.998160</td>\n",
       "      <td>0.999808</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.062660</td>\n",
       "      <td>0.999400</td>\n",
       "      <td>6.051660e-07</td>\n",
       "      <td>0.999218</td>\n",
       "      <td>9.887495e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>9.910758e-01</td>\n",
       "      <td>0.996380</td>\n",
       "      <td>0.060530</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>3.291232e-10</td>\n",
       "      <td>0.999156</td>\n",
       "      <td>0.999972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.173273e-01</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.842315</td>\n",
       "      <td>0.999846</td>\n",
       "      <td>0.999850</td>\n",
       "      <td>0.993182</td>\n",
       "      <td>0.991385</td>\n",
       "      <td>9.993092e-01</td>\n",
       "      <td>0.990580</td>\n",
       "      <td>9.298694e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999251</td>\n",
       "      <td>0.999412</td>\n",
       "      <td>9.096835e-01</td>\n",
       "      <td>0.943529</td>\n",
       "      <td>0.998246</td>\n",
       "      <td>0.999865</td>\n",
       "      <td>0.990495</td>\n",
       "      <td>9.983254e-01</td>\n",
       "      <td>0.989573</td>\n",
       "      <td>0.995251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.648160e-01</td>\n",
       "      <td>0.866365</td>\n",
       "      <td>0.029612</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.809642</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.997936</td>\n",
       "      <td>9.970183e-01</td>\n",
       "      <td>0.997478</td>\n",
       "      <td>9.900954e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.999340</td>\n",
       "      <td>9.656271e-01</td>\n",
       "      <td>0.981899</td>\n",
       "      <td>0.003091</td>\n",
       "      <td>0.003208</td>\n",
       "      <td>0.981044</td>\n",
       "      <td>1.564270e-06</td>\n",
       "      <td>0.997203</td>\n",
       "      <td>0.999778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.336944e-09</td>\n",
       "      <td>0.999086</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.999354</td>\n",
       "      <td>0.999245</td>\n",
       "      <td>0.978525</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>9.975210e-01</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>2.931903e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999019</td>\n",
       "      <td>0.998785</td>\n",
       "      <td>3.771101e-09</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.997536</td>\n",
       "      <td>0.998807</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>9.967191e-01</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.997343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.522420e-01</td>\n",
       "      <td>0.999415</td>\n",
       "      <td>0.719807</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.999518</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.997145</td>\n",
       "      <td>8.787863e-01</td>\n",
       "      <td>0.996644</td>\n",
       "      <td>9.929014e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999207</td>\n",
       "      <td>0.997683</td>\n",
       "      <td>9.519899e-01</td>\n",
       "      <td>0.970967</td>\n",
       "      <td>0.997346</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>9.258445e-02</td>\n",
       "      <td>0.996303</td>\n",
       "      <td>0.999273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "0  9.910194e-01  0.000306  0.998160  0.999808  0.000001  0.062660  0.999400   \n",
       "1  9.173273e-01  0.999841  0.842315  0.999846  0.999850  0.993182  0.991385   \n",
       "2  9.648160e-01  0.866365  0.029612  0.000288  0.809642  0.999986  0.997936   \n",
       "3  4.336944e-09  0.999086  0.000009  0.999354  0.999245  0.978525  0.000538   \n",
       "4  9.522420e-01  0.999415  0.719807  0.000378  0.999518  0.999991  0.997145   \n",
       "\n",
       "            7         8             9    ...       118       119  \\\n",
       "0  6.051660e-07  0.999218  9.887495e-01  ...  0.000602  0.000259   \n",
       "1  9.993092e-01  0.990580  9.298694e-04  ...  0.999251  0.999412   \n",
       "2  9.970183e-01  0.997478  9.900954e-01  ...  0.000778  0.999340   \n",
       "3  9.975210e-01  0.000504  2.931903e-10  ...  0.999019  0.998785   \n",
       "4  8.787863e-01  0.996644  9.929014e-01  ...  0.999207  0.997683   \n",
       "\n",
       "            120       121       122       123       124           125  \\\n",
       "0  9.910758e-01  0.996380  0.060530  0.000023  0.000802  3.291232e-10   \n",
       "1  9.096835e-01  0.943529  0.998246  0.999865  0.990495  9.983254e-01   \n",
       "2  9.656271e-01  0.981899  0.003091  0.003208  0.981044  1.564270e-06   \n",
       "3  3.771101e-09  0.000118  0.997536  0.998807  0.999945  9.967191e-01   \n",
       "4  9.519899e-01  0.970967  0.997346  0.999901  0.000750  9.258445e-02   \n",
       "\n",
       "        126       127  \n",
       "0  0.999156  0.999972  \n",
       "1  0.989573  0.995251  \n",
       "2  0.997203  0.999778  \n",
       "3  0.000424  0.997343  \n",
       "4  0.996303  0.999273  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_features).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120000, 128), (120000,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.200000e+05</td>\n",
       "      <td>1.200000e+05</td>\n",
       "      <td>1.200000e+05</td>\n",
       "      <td>1.200000e+05</td>\n",
       "      <td>1.200000e+05</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>1.200000e+05</td>\n",
       "      <td>1.200000e+05</td>\n",
       "      <td>1.200000e+05</td>\n",
       "      <td>1.200000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200000e+05</td>\n",
       "      <td>1.200000e+05</td>\n",
       "      <td>1.200000e+05</td>\n",
       "      <td>1.200000e+05</td>\n",
       "      <td>1.200000e+05</td>\n",
       "      <td>1.200000e+05</td>\n",
       "      <td>1.200000e+05</td>\n",
       "      <td>1.200000e+05</td>\n",
       "      <td>1.200000e+05</td>\n",
       "      <td>120000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.033561e-01</td>\n",
       "      <td>6.348078e-01</td>\n",
       "      <td>7.125301e-01</td>\n",
       "      <td>5.455635e-01</td>\n",
       "      <td>6.641388e-01</td>\n",
       "      <td>0.550037</td>\n",
       "      <td>9.764564e-01</td>\n",
       "      <td>5.338461e-01</td>\n",
       "      <td>9.757876e-01</td>\n",
       "      <td>8.587283e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>7.672417e-01</td>\n",
       "      <td>7.096099e-01</td>\n",
       "      <td>9.022319e-01</td>\n",
       "      <td>9.416335e-01</td>\n",
       "      <td>5.764372e-01</td>\n",
       "      <td>6.417290e-01</td>\n",
       "      <td>6.779555e-01</td>\n",
       "      <td>3.917399e-01</td>\n",
       "      <td>9.752954e-01</td>\n",
       "      <td>0.990705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.331182e-01</td>\n",
       "      <td>4.534950e-01</td>\n",
       "      <td>3.607989e-01</td>\n",
       "      <td>4.968136e-01</td>\n",
       "      <td>4.316803e-01</td>\n",
       "      <td>0.479161</td>\n",
       "      <td>1.390873e-01</td>\n",
       "      <td>4.706822e-01</td>\n",
       "      <td>1.397909e-01</td>\n",
       "      <td>3.065024e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.860230e-01</td>\n",
       "      <td>4.156960e-01</td>\n",
       "      <td>2.344344e-01</td>\n",
       "      <td>1.847557e-01</td>\n",
       "      <td>4.772537e-01</td>\n",
       "      <td>4.513941e-01</td>\n",
       "      <td>4.363293e-01</td>\n",
       "      <td>4.664476e-01</td>\n",
       "      <td>1.403415e-01</td>\n",
       "      <td>0.088116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.426757e-13</td>\n",
       "      <td>1.275966e-08</td>\n",
       "      <td>1.955757e-13</td>\n",
       "      <td>4.631989e-07</td>\n",
       "      <td>3.566260e-14</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>1.579571e-08</td>\n",
       "      <td>1.115381e-11</td>\n",
       "      <td>1.321325e-08</td>\n",
       "      <td>2.560094e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>1.051135e-10</td>\n",
       "      <td>3.384914e-10</td>\n",
       "      <td>2.340012e-13</td>\n",
       "      <td>1.016145e-11</td>\n",
       "      <td>4.781780e-09</td>\n",
       "      <td>1.557674e-11</td>\n",
       "      <td>2.066126e-12</td>\n",
       "      <td>4.653072e-14</td>\n",
       "      <td>1.029638e-08</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.576712e-01</td>\n",
       "      <td>1.527847e-02</td>\n",
       "      <td>4.768665e-01</td>\n",
       "      <td>9.299605e-04</td>\n",
       "      <td>8.174857e-02</td>\n",
       "      <td>0.022082</td>\n",
       "      <td>9.970088e-01</td>\n",
       "      <td>5.052091e-04</td>\n",
       "      <td>9.965470e-01</td>\n",
       "      <td>9.578173e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>6.795740e-01</td>\n",
       "      <td>2.365637e-01</td>\n",
       "      <td>9.570974e-01</td>\n",
       "      <td>9.764688e-01</td>\n",
       "      <td>2.775765e-03</td>\n",
       "      <td>1.603328e-02</td>\n",
       "      <td>7.066223e-02</td>\n",
       "      <td>1.852675e-07</td>\n",
       "      <td>9.961751e-01</td>\n",
       "      <td>0.999107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.786124e-01</td>\n",
       "      <td>9.941993e-01</td>\n",
       "      <td>9.220235e-01</td>\n",
       "      <td>9.995912e-01</td>\n",
       "      <td>9.822245e-01</td>\n",
       "      <td>0.991185</td>\n",
       "      <td>9.983859e-01</td>\n",
       "      <td>7.922492e-01</td>\n",
       "      <td>9.980929e-01</td>\n",
       "      <td>9.844503e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>9.978308e-01</td>\n",
       "      <td>9.962118e-01</td>\n",
       "      <td>9.787726e-01</td>\n",
       "      <td>9.874736e-01</td>\n",
       "      <td>9.771563e-01</td>\n",
       "      <td>9.953632e-01</td>\n",
       "      <td>9.794073e-01</td>\n",
       "      <td>3.481912e-03</td>\n",
       "      <td>9.978867e-01</td>\n",
       "      <td>0.999723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.870144e-01</td>\n",
       "      <td>9.998914e-01</td>\n",
       "      <td>9.814275e-01</td>\n",
       "      <td>9.999000e-01</td>\n",
       "      <td>9.998310e-01</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>9.992296e-01</td>\n",
       "      <td>9.983839e-01</td>\n",
       "      <td>9.990538e-01</td>\n",
       "      <td>9.927348e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>9.995388e-01</td>\n",
       "      <td>9.997169e-01</td>\n",
       "      <td>9.873961e-01</td>\n",
       "      <td>9.938588e-01</td>\n",
       "      <td>9.974900e-01</td>\n",
       "      <td>9.999135e-01</td>\n",
       "      <td>9.887532e-01</td>\n",
       "      <td>9.895194e-01</td>\n",
       "      <td>9.989492e-01</td>\n",
       "      <td>0.999934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.981091e-01</td>\n",
       "      <td>9.999942e-01</td>\n",
       "      <td>9.999406e-01</td>\n",
       "      <td>9.999819e-01</td>\n",
       "      <td>9.999938e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.998997e-01</td>\n",
       "      <td>9.998221e-01</td>\n",
       "      <td>9.998659e-01</td>\n",
       "      <td>9.992118e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>9.999920e-01</td>\n",
       "      <td>9.999921e-01</td>\n",
       "      <td>9.981886e-01</td>\n",
       "      <td>9.992176e-01</td>\n",
       "      <td>9.995348e-01</td>\n",
       "      <td>9.999878e-01</td>\n",
       "      <td>9.999994e-01</td>\n",
       "      <td>9.993986e-01</td>\n",
       "      <td>9.998528e-01</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2             3             4    \\\n",
       "count  1.200000e+05  1.200000e+05  1.200000e+05  1.200000e+05  1.200000e+05   \n",
       "mean   9.033561e-01  6.348078e-01  7.125301e-01  5.455635e-01  6.641388e-01   \n",
       "std    2.331182e-01  4.534950e-01  3.607989e-01  4.968136e-01  4.316803e-01   \n",
       "min    2.426757e-13  1.275966e-08  1.955757e-13  4.631989e-07  3.566260e-14   \n",
       "25%    9.576712e-01  1.527847e-02  4.768665e-01  9.299605e-04  8.174857e-02   \n",
       "50%    9.786124e-01  9.941993e-01  9.220235e-01  9.995912e-01  9.822245e-01   \n",
       "75%    9.870144e-01  9.998914e-01  9.814275e-01  9.999000e-01  9.998310e-01   \n",
       "max    9.981091e-01  9.999942e-01  9.999406e-01  9.999819e-01  9.999938e-01   \n",
       "\n",
       "                 5             6             7             8             9    \\\n",
       "count  120000.000000  1.200000e+05  1.200000e+05  1.200000e+05  1.200000e+05   \n",
       "mean        0.550037  9.764564e-01  5.338461e-01  9.757876e-01  8.587283e-01   \n",
       "std         0.479161  1.390873e-01  4.706822e-01  1.397909e-01  3.065024e-01   \n",
       "min         0.000055  1.579571e-08  1.115381e-11  1.321325e-08  2.560094e-12   \n",
       "25%         0.022082  9.970088e-01  5.052091e-04  9.965470e-01  9.578173e-01   \n",
       "50%         0.991185  9.983859e-01  7.922492e-01  9.980929e-01  9.844503e-01   \n",
       "75%         0.999992  9.992296e-01  9.983839e-01  9.990538e-01  9.927348e-01   \n",
       "max         1.000000  9.998997e-01  9.998221e-01  9.998659e-01  9.992118e-01   \n",
       "\n",
       "       ...           118           119           120           121  \\\n",
       "count  ...  1.200000e+05  1.200000e+05  1.200000e+05  1.200000e+05   \n",
       "mean   ...  7.672417e-01  7.096099e-01  9.022319e-01  9.416335e-01   \n",
       "std    ...  3.860230e-01  4.156960e-01  2.344344e-01  1.847557e-01   \n",
       "min    ...  1.051135e-10  3.384914e-10  2.340012e-13  1.016145e-11   \n",
       "25%    ...  6.795740e-01  2.365637e-01  9.570974e-01  9.764688e-01   \n",
       "50%    ...  9.978308e-01  9.962118e-01  9.787726e-01  9.874736e-01   \n",
       "75%    ...  9.995388e-01  9.997169e-01  9.873961e-01  9.938588e-01   \n",
       "max    ...  9.999920e-01  9.999921e-01  9.981886e-01  9.992176e-01   \n",
       "\n",
       "                122           123           124           125           126  \\\n",
       "count  1.200000e+05  1.200000e+05  1.200000e+05  1.200000e+05  1.200000e+05   \n",
       "mean   5.764372e-01  6.417290e-01  6.779555e-01  3.917399e-01  9.752954e-01   \n",
       "std    4.772537e-01  4.513941e-01  4.363293e-01  4.664476e-01  1.403415e-01   \n",
       "min    4.781780e-09  1.557674e-11  2.066126e-12  4.653072e-14  1.029638e-08   \n",
       "25%    2.775765e-03  1.603328e-02  7.066223e-02  1.852675e-07  9.961751e-01   \n",
       "50%    9.771563e-01  9.953632e-01  9.794073e-01  3.481912e-03  9.978867e-01   \n",
       "75%    9.974900e-01  9.999135e-01  9.887532e-01  9.895194e-01  9.989492e-01   \n",
       "max    9.995348e-01  9.999878e-01  9.999994e-01  9.993986e-01  9.998528e-01   \n",
       "\n",
       "                 127  \n",
       "count  120000.000000  \n",
       "mean        0.990705  \n",
       "std         0.088116  \n",
       "min         0.000028  \n",
       "25%         0.999107  \n",
       "50%         0.999723  \n",
       "75%         0.999934  \n",
       "max         0.999999  \n",
       "\n",
       "[8 rows x 128 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_features).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegressionCV\n",
    "# searchCV = LogisticRegressionCV(\n",
    "#         Cs=7\n",
    "#         ,penalty='l1'\n",
    "#         ,scoring='roc_auc'\n",
    "#         ,cv=3\n",
    "#         ,random_state=42\n",
    "#         ,max_iter=10000\n",
    "#         ,fit_intercept=True\n",
    "#         ,n_jobs = -1\n",
    "#         ,solver = 'saga'\n",
    "#     )\n",
    "# latent_cv = searchCV.fit(train_features, train_labels)\n",
    "# print(latent_cv.scores_[1].max())\n",
    "\n",
    "# raw_cv = searchCV.fit(train[X], train[Y])\n",
    "# print(raw_cv.scores_[1].max())\n",
    "\n",
    "# md5_features_cv = searchCV.fit(train[md5_features], train[Y])\n",
    "# print(md5_features_cv.scores_[1].max())\n",
    "\n",
    "# non_md5_features_cv = searchCV.fit(train[non_md5_features], train[Y])\n",
    "# print(non_md5_features_cv.scores_[1].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "searchCV = LogisticRegressionCV(\n",
    "        Cs=5\n",
    "        ,penalty='l2'\n",
    "        ,scoring='roc_auc'\n",
    "        ,cv=3\n",
    "        ,random_state=42\n",
    "        ,max_iter=100\n",
    "        ,fit_intercept=True\n",
    "        ,n_jobs = -1\n",
    "        \n",
    "    )\n",
    "latent_cv2 = searchCV.fit(train_features, train_labels)\n",
    "print(latent_cv2.scores_[1].max())\n",
    "\n",
    "raw_cv2 = searchCV.fit(train[X], train[Y])\n",
    "print(raw_cv2.scores_[1].max())\n",
    "\n",
    "md5_features_cv2 = searchCV.fit(train[md5_features], train[Y])\n",
    "print(md5_features_cv2.scores_[1].max())\n",
    "\n",
    "non_md5_features_cv2 = searchCV.fit(train[non_md5_features], train[Y])\n",
    "print(non_md5_features_cv2.scores_[1].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(X, Y, name):\n",
    "    df = pd.concat([X, Y], axis = 1) \n",
    "    df.to_csv(name)\n",
    "    \n",
    "    \n",
    "save_csv(pd.DataFrame(train_features) , pd.DataFrame(train_labels), 'latent_no_0.csv')\n",
    "save_csv( train[X], train[Y], 'raw_no_0.csv')\n",
    "save_csv( train[md5_features], train[Y], 'md5_features_no_0.csv')\n",
    "save_csv( train[non_md5_features], train[Y], 'non_md5_features_no_0.csv')\n",
    "\n",
    "\n",
    "save_csv(pd.DataFrame(test_features) , pd.DataFrame(test_labels), 'latent_test_no_0.csv')\n",
    "save_csv( test[X], test[Y], 'raw_test_no_0.csv')\n",
    "save_csv( test[md5_features], test[Y], 'md5_features_test_no_0.csv')\n",
    "save_csv( test[non_md5_features], test[Y], 'non_md5_features_test_no_0.csv')\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "clf = LogisticRegression(penalty = 'none', max_iter = 10000)\n",
    "clf.fit(train_features, train_labels)\n",
    "train_predictions, test_predictions = \\\n",
    "  clf.predict(train_features), clf.predict(test_features)\n",
    "\n",
    "print(\"on latent features, out training and test aucs are\")\n",
    "print(\"train\",roc_auc_score(train_predictions, train_labels))\n",
    "print(\"test\", roc_auc_score(test_predictions, test_labels))\n",
    "   \n",
    "clf =LogisticRegression(penalty = 'l2', max_iter = 10000, solver = 'saga')\n",
    "clf.fit(train[X], train[Y])\n",
    "train_predictions, test_predictions = clf.predict(train[X]), \\\n",
    "                                      clf.predict(test[X])\n",
    "\n",
    "\n",
    "predictions = clf.predict_proba(test[X])\n",
    "roc_auc_score(predictions, test[Y])\n",
    "print(\"running on the raw feature data\",\n",
    "       roc_auc_score(train_predictions, train[Y]),\n",
    "       roc_auc_score(test_predictions, test[Y]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "clf = LogisticRegression(penalty = 'l1', solver = 'liblinear')\n",
    "clf.fit(train_features, train_labels)\n",
    "train_predictions, test_predictions = \\\n",
    "  clf.predict(train_features), clf.predict(test_features)\n",
    "\n",
    "print(\"on latent features, out training and test aucs are\")\n",
    "print(\"train\",roc_auc_score(train_predictions, train_labels))\n",
    "print(\"test\", roc_auc_score(test_predictions, test_labels))\n",
    "\n",
    "\n",
    "\n",
    "clf =LogisticRegression(penalty = 'l1', solver = 'liblinear')\n",
    "clf.fit(train[X], train[Y])\n",
    "train_predictions, test_predictions = clf.predict(train[X]), \\\n",
    "                                      clf.predict(test[X])\n",
    "\n",
    "\n",
    "predictions = clf.predict(test[X])\n",
    "roc_auc_score(predictions, test[Y])\n",
    "print(\"running on the raw feature data\",\n",
    "       roc_auc_score(train_predictions, train[Y]),\n",
    "       roc_auc_score(test_predictions, test[Y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> <font color='orange'> Running RBM on original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>z261</th>\n",
       "      <th>z498</th>\n",
       "      <th>z52</th>\n",
       "      <th>z178</th>\n",
       "      <th>z87</th>\n",
       "      <th>z374</th>\n",
       "      <th>z319</th>\n",
       "      <th>z26</th>\n",
       "      <th>z257</th>\n",
       "      <th>z264</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5075 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  z261  z498  z52  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0  0.0   \n",
       "\n",
       "   z178  z87  z374  z319  z26  z257  z264  \n",
       "0   0.0  0.0   0.0   0.0  0.0   0.0   0.0  \n",
       "1   0.0  0.0   0.0   0.0  0.0   0.0   0.0  \n",
       "2   0.0  0.0   0.0   0.0  0.0   0.0   0.0  \n",
       "3   0.0  0.0   0.0   0.0  0.0   0.0   0.0  \n",
       "4   0.0  0.0   0.0   0.0  0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 5075 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30000, 5074), (10000, 5074), (30000, 1418), (10000, 1418))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size= 40000\n",
    "test_size= 0.25\n",
    "train_size= 1- test_size\n",
    "\n",
    "orig_train_sample= preprocessed_DF.sample(sample_size, random_state= 42)\n",
    "\n",
    "\n",
    "orig_test_sample= orig_train_sample.iloc[int(train_size*sample_size) : ]\n",
    "orig_train_sample= orig_train_sample.iloc[: int(train_size*sample_size)]\n",
    "\n",
    "\n",
    "ytrain_sample= orig_train_sample['label']\n",
    "ytest_sample= orig_test_sample['label']\n",
    "\n",
    "\n",
    "#### Final Sample Train using all features ####\n",
    "orig_train_sample.drop('label', axis=1, inplace= True)\n",
    "orig_test_sample.drop('label', axis=1, inplace= True)\n",
    "\n",
    "\n",
    "#### Final Sample Train using only MD5 features ####\n",
    "md5_orig_train_sample= orig_train_sample.drop(md5_features, axis=1)\n",
    "md5_orig_test_sample= orig_test_sample.drop(md5_features, axis=1)\n",
    "\n",
    "\n",
    "#### Final Sample Train using only DSP features ####\n",
    "md5_orig_train_sample= orig_train_sample.drop(non_md5_features, axis=1)\n",
    "md5_orig_test_sample= orig_test_sample.drop(non_md5_features, axis=1)\n",
    "\n",
    "\n",
    "orig_train_sample.shape, orig_test_sample.shape, md5_orig_train_sample.shape, md5_orig_test_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial features = 5074\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_feats_selected</th>\n",
       "      <th>list_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.02500</th>\n",
       "      <td>119</td>\n",
       "      <td>[84, 87, 219, 358, 390, 477, 595, 631, 975, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.03375</th>\n",
       "      <td>217</td>\n",
       "      <td>[84, 85, 87, 219, 358, 390, 477, 528, 530, 562...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.04250</th>\n",
       "      <td>293</td>\n",
       "      <td>[84, 85, 87, 128, 219, 358, 390, 477, 528, 530...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.05125</th>\n",
       "      <td>388</td>\n",
       "      <td>[2, 84, 85, 87, 128, 219, 284, 358, 361, 390, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.06000</th>\n",
       "      <td>478</td>\n",
       "      <td>[2, 4, 31, 62, 84, 85, 87, 128, 157, 219, 284,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         n_feats_selected                                      list_features\n",
       "0.02500               119  [84, 87, 219, 358, 390, 477, 595, 631, 975, 11...\n",
       "0.03375               217  [84, 85, 87, 219, 358, 390, 477, 528, 530, 562...\n",
       "0.04250               293  [84, 85, 87, 128, 219, 358, 390, 477, 528, 530...\n",
       "0.05125               388  [2, 84, 85, 87, 128, 219, 284, 358, 361, 390, ...\n",
       "0.06000               478  [2, 4, 31, 62, 84, 85, 87, 128, 157, 219, 284,..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_C_parameters =   np.linspace(0.025, 0.06, 5)  #np.arange(0.00125, 0.005, 5)  #list(np.linspace(0.001, 0.125, 4))  # or = [0.00050, 0.00075, 0.00100]\n",
    "\n",
    "features_selected= reduced_lasso_final= reduced_models_lasso(\n",
    "                                    values_C= list_C_parameters,\n",
    "                                    train= orig_train_sample,\n",
    "                                    ytrain= ytrain_sample,\n",
    "                                    random_state=42,\n",
    "                                    min_n_feats= 20,\n",
    "                                    max_n_feats= 5000,\n",
    "                                    solver= 'liblinear')    \n",
    "\n",
    "reduced_lasso_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Initial X_train e X_test shapes are:  (30000, 5074) (10000, 5074) \u001b[0m \n",
      "\n",
      "\n",
      "\t \u001b[1mITERATION 1/5 \u001b[0m\n",
      "\t Current Grid of Parameters is {'clf__C': 1, 'clf__penalty': 'none', 'clf__solver': 'saga', 'lasso__estimator__C': 0.025}\n",
      "\n",
      "\u001b[1mROC Train is 0.6281, ROC Test is 0.5745\u001b[0m\n",
      "\n",
      "\t \u001b[1mITERATION 2/5 \u001b[0m\n",
      "\t Current Grid of Parameters is {'clf__C': 1, 'clf__penalty': 'none', 'clf__solver': 'saga', 'lasso__estimator__C': 0.03375}\n",
      "\n",
      "\u001b[1mROC Train is 0.6429, ROC Test is 0.5741\u001b[0m\n",
      "\n",
      "\t \u001b[1mITERATION 3/5 \u001b[0m\n",
      "\t Current Grid of Parameters is {'clf__C': 1, 'clf__penalty': 'none', 'clf__solver': 'saga', 'lasso__estimator__C': 0.0425}\n",
      "\n",
      "\u001b[1mROC Train is 0.657, ROC Test is 0.5763\u001b[0m\n",
      "\n",
      "\t \u001b[1mITERATION 4/5 \u001b[0m\n",
      "\t Current Grid of Parameters is {'clf__C': 1, 'clf__penalty': 'none', 'clf__solver': 'saga', 'lasso__estimator__C': 0.05125}\n",
      "\n",
      "\u001b[1mROC Train is 0.669, ROC Test is 0.5755\u001b[0m\n",
      "\n",
      "\t \u001b[1mITERATION 5/5 \u001b[0m\n",
      "\t Current Grid of Parameters is {'clf__C': 1, 'clf__penalty': 'none', 'clf__solver': 'saga', 'lasso__estimator__C': 0.06}\n",
      "\n",
      "\u001b[1mROC Train is 0.6809, ROC Test is 0.5759\u001b[0m\n",
      "execution time (min)= 3.7  finished at  2020-08-24 18:10:12.372252\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diz_params</th>\n",
       "      <th>degree_overfitting(%)</th>\n",
       "      <th>Train_AUC</th>\n",
       "      <th>Test_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'clf__C': 1, 'clf__penalty': 'none', 'clf__so...</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.6570</td>\n",
       "      <td>0.5763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'clf__C': 1, 'clf__penalty': 'none', 'clf__so...</td>\n",
       "      <td>10.50</td>\n",
       "      <td>0.6809</td>\n",
       "      <td>0.5759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'clf__C': 1, 'clf__penalty': 'none', 'clf__so...</td>\n",
       "      <td>9.35</td>\n",
       "      <td>0.6690</td>\n",
       "      <td>0.5755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'clf__C': 1, 'clf__penalty': 'none', 'clf__so...</td>\n",
       "      <td>5.36</td>\n",
       "      <td>0.6281</td>\n",
       "      <td>0.5745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'clf__C': 1, 'clf__penalty': 'none', 'clf__so...</td>\n",
       "      <td>6.88</td>\n",
       "      <td>0.6429</td>\n",
       "      <td>0.5741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          diz_params  degree_overfitting(%)  \\\n",
       "3  {'clf__C': 1, 'clf__penalty': 'none', 'clf__so...                   8.07   \n",
       "5  {'clf__C': 1, 'clf__penalty': 'none', 'clf__so...                  10.50   \n",
       "4  {'clf__C': 1, 'clf__penalty': 'none', 'clf__so...                   9.35   \n",
       "1  {'clf__C': 1, 'clf__penalty': 'none', 'clf__so...                   5.36   \n",
       "2  {'clf__C': 1, 'clf__penalty': 'none', 'clf__so...                   6.88   \n",
       "\n",
       "   Train_AUC  Test_AUC  \n",
       "3     0.6570    0.5763  \n",
       "5     0.6809    0.5759  \n",
       "4     0.6690    0.5755  \n",
       "1     0.6281    0.5745  \n",
       "2     0.6429    0.5741  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Grid Search without Cross Validation\n",
    "final_list_C= list(reduced_lasso_final.index)\n",
    "\n",
    "logi= Pipeline([\n",
    "      ('lasso', SelectFromModel(LogisticRegression(penalty='l1' ,random_state= 42, \n",
    "                                                   class_weight='balanced', solver= 'liblinear',\n",
    "                                                  max_iter=1000) )), \n",
    "      ('clf', LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000), )   \n",
    "                        ])\n",
    "\n",
    "\n",
    "param_grid_lasso =  [    {\n",
    "                'lasso__estimator__C': final_list_C,\n",
    "                 'clf__penalty': ['none'], \n",
    "                'clf__solver': ['saga' ],\n",
    "                'clf__C': [1] # no needed, penalty is always set to 'none' bcs in the end we need to use a simple LR..\n",
    "                    }  ]\n",
    "\n",
    "\n",
    "###Â Without CV\n",
    "    \n",
    "    \n",
    "grid_logistic_no_cv = run_model_no_cv(estimator=logi,\n",
    "                                        X_train=orig_train_sample, \n",
    "                                        X_test= orig_test_sample,\n",
    "                                        ytrain= ytrain_sample,\n",
    "                                        ytest= ytest_sample,\n",
    "                                        param_grid=param_grid_lasso,\n",
    "                                        print_model=False)\n",
    "grid_logistic_no_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_lasso__estimator__C</th>\n",
       "      <th>n_feats_selected</th>\n",
       "      <th>Train_AUC</th>\n",
       "      <th>Test_AUC</th>\n",
       "      <th>degree_overfitting(%)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DSP + MD5</th>\n",
       "      <td>0.04250</td>\n",
       "      <td>293</td>\n",
       "      <td>0.6570</td>\n",
       "      <td>0.5763</td>\n",
       "      <td>8.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DSP + MD5</th>\n",
       "      <td>0.06000</td>\n",
       "      <td>478</td>\n",
       "      <td>0.6809</td>\n",
       "      <td>0.5759</td>\n",
       "      <td>10.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DSP + MD5</th>\n",
       "      <td>0.05125</td>\n",
       "      <td>388</td>\n",
       "      <td>0.6690</td>\n",
       "      <td>0.5755</td>\n",
       "      <td>9.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DSP + MD5</th>\n",
       "      <td>0.02500</td>\n",
       "      <td>119</td>\n",
       "      <td>0.6281</td>\n",
       "      <td>0.5745</td>\n",
       "      <td>5.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DSP + MD5</th>\n",
       "      <td>0.03375</td>\n",
       "      <td>217</td>\n",
       "      <td>0.6429</td>\n",
       "      <td>0.5741</td>\n",
       "      <td>6.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           param_lasso__estimator__C  n_feats_selected  Train_AUC  Test_AUC  \\\n",
       "features                                                                      \n",
       "DSP + MD5                    0.04250               293     0.6570    0.5763   \n",
       "DSP + MD5                    0.06000               478     0.6809    0.5759   \n",
       "DSP + MD5                    0.05125               388     0.6690    0.5755   \n",
       "DSP + MD5                    0.02500               119     0.6281    0.5745   \n",
       "DSP + MD5                    0.03375               217     0.6429    0.5741   \n",
       "\n",
       "           degree_overfitting(%)  \n",
       "features                          \n",
       "DSP + MD5                   8.07  \n",
       "DSP + MD5                  10.50  \n",
       "DSP + MD5                   9.35  \n",
       "DSP + MD5                   5.36  \n",
       "DSP + MD5                   6.88  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_logistic_no_cv['param_lasso__estimator__C']= \\\n",
    "                    grid_logistic_no_cv['diz_params'].apply(lambda x: x['lasso__estimator__C'] )\n",
    "\n",
    "\n",
    "final_complete_results= {}  #combining results_grids and features_selected to have a complete summary in one single df\n",
    "\n",
    "features_selected.index.name= 'param_lasso__estimator__C'\n",
    "final_complete_results= features_selected.reset_index().merge(grid_logistic_no_cv).sort_values(\n",
    "                                                                        by= 'Test_AUC', ascending= False)\n",
    "\n",
    "final_complete_results= final_complete_results[['param_lasso__estimator__C', 'n_feats_selected',\n",
    "                                                     'Train_AUC','Test_AUC', 'degree_overfitting(%)']]\n",
    "\n",
    "\n",
    "final_complete_results['features']= 'DSP + MD5'\n",
    "final_complete_results.set_index('features', inplace= True)\n",
    "\n",
    "final_complete_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> Using only md5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial features = 1418\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_feats_selected</th>\n",
       "      <th>list_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.02500</th>\n",
       "      <td>86</td>\n",
       "      <td>[IBE7753, IBE7773, IBE7777, IBE7780, IBE7801, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.03375</th>\n",
       "      <td>142</td>\n",
       "      <td>[IBE7746, IBE7753, IBE7754, IBE7773, IBE7777, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.04250</th>\n",
       "      <td>212</td>\n",
       "      <td>[IBE7732, IBE7746, IBE7753, IBE7754, IBE7763, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.05125</th>\n",
       "      <td>266</td>\n",
       "      <td>[IBE2076_IBE_PREMIER_SOCIALCONCERNCAUSESSUPPOR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.06000</th>\n",
       "      <td>336</td>\n",
       "      <td>[IBE2076_IBE_PREMIER_SOCIALCONCERNCAUSESSUPPOR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         n_feats_selected                                      list_features\n",
       "0.02500                86  [IBE7753, IBE7773, IBE7777, IBE7780, IBE7801, ...\n",
       "0.03375               142  [IBE7746, IBE7753, IBE7754, IBE7773, IBE7777, ...\n",
       "0.04250               212  [IBE7732, IBE7746, IBE7753, IBE7754, IBE7763, ...\n",
       "0.05125               266  [IBE2076_IBE_PREMIER_SOCIALCONCERNCAUSESSUPPOR...\n",
       "0.06000               336  [IBE2076_IBE_PREMIER_SOCIALCONCERNCAUSESSUPPOR..."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_C_parameters =   np.linspace(0.025, 0.06, 5)  #np.arange(0.00125, 0.005, 5)  #list(np.linspace(0.001, 0.125, 4))  # or = [0.00050, 0.00075, 0.00100]\n",
    "\n",
    "md5_features_selected= md5_reduced_lasso_final= reduced_models_lasso(\n",
    "                                    values_C= list_C_parameters,\n",
    "                                    train= md5_orig_train_sample,\n",
    "                                    ytrain= ytrain_sample,\n",
    "                                    random_state=42,\n",
    "                                    min_n_feats= 20,\n",
    "                                    max_n_feats= 500,\n",
    "                                    solver= 'liblinear')    \n",
    "\n",
    "md5_reduced_lasso_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Initial X_train e X_test shapes are:  (30000, 1418) (10000, 1418) \u001b[0m \n",
      "\n",
      "\n",
      "\t \u001b[1mITERATION 1/5 \u001b[0m\n",
      "\t Current Grid of Parameters is {'clf__C': 1, 'clf__penalty': 'none', 'clf__solver': 'saga', 'lasso__estimator__C': 0.025}\n",
      "\n",
      "\u001b[1mROC Train is 0.5998, ROC Test is 0.5541\u001b[0m\n",
      "Pipeline(steps=[('lasso',\n",
      "                 SelectFromModel(estimator=LogisticRegression(C=0.025,\n",
      "                                                              class_weight='balanced',\n",
      "                                                              penalty='l1',\n",
      "                                                              random_state=42,\n",
      "                                                              solver='liblinear'))),\n",
      "                ('clf',\n",
      "                 LogisticRegression(C=1, class_weight='balanced',\n",
      "                                    penalty='none', random_state=42,\n",
      "                                    solver='saga'))])\n",
      "\n",
      "\t \u001b[1mITERATION 2/5 \u001b[0m\n",
      "\t Current Grid of Parameters is {'clf__C': 1, 'clf__penalty': 'none', 'clf__solver': 'saga', 'lasso__estimator__C': 0.03375}\n",
      "\n",
      "\u001b[1mROC Train is 0.6131, ROC Test is 0.5542\u001b[0m\n",
      "Pipeline(steps=[('lasso',\n",
      "                 SelectFromModel(estimator=LogisticRegression(C=0.03375,\n",
      "                                                              class_weight='balanced',\n",
      "                                                              penalty='l1',\n",
      "                                                              random_state=42,\n",
      "                                                              solver='liblinear'))),\n",
      "                ('clf',\n",
      "                 LogisticRegression(C=1, class_weight='balanced',\n",
      "                                    penalty='none', random_state=42,\n",
      "                                    solver='saga'))])\n",
      "\n",
      "\t \u001b[1mITERATION 3/5 \u001b[0m\n",
      "\t Current Grid of Parameters is {'clf__C': 1, 'clf__penalty': 'none', 'clf__solver': 'saga', 'lasso__estimator__C': 0.0425}\n",
      "\n",
      "\u001b[1mROC Train is 0.6215, ROC Test is 0.5591\u001b[0m\n",
      "Pipeline(steps=[('lasso',\n",
      "                 SelectFromModel(estimator=LogisticRegression(C=0.0425,\n",
      "                                                              class_weight='balanced',\n",
      "                                                              penalty='l1',\n",
      "                                                              random_state=42,\n",
      "                                                              solver='liblinear'))),\n",
      "                ('clf',\n",
      "                 LogisticRegression(C=1, class_weight='balanced',\n",
      "                                    penalty='none', random_state=42,\n",
      "                                    solver='saga'))])\n",
      "\n",
      "\t \u001b[1mITERATION 4/5 \u001b[0m\n",
      "\t Current Grid of Parameters is {'clf__C': 1, 'clf__penalty': 'none', 'clf__solver': 'saga', 'lasso__estimator__C': 0.05125}\n",
      "\n",
      "\u001b[1mROC Train is 0.6286, ROC Test is 0.5592\u001b[0m\n",
      "Pipeline(steps=[('lasso',\n",
      "                 SelectFromModel(estimator=LogisticRegression(C=0.05125,\n",
      "                                                              class_weight='balanced',\n",
      "                                                              penalty='l1',\n",
      "                                                              random_state=42,\n",
      "                                                              solver='liblinear'))),\n",
      "                ('clf',\n",
      "                 LogisticRegression(C=1, class_weight='balanced',\n",
      "                                    penalty='none', random_state=42,\n",
      "                                    solver='saga'))])\n",
      "\n",
      "\t \u001b[1mITERATION 5/5 \u001b[0m\n",
      "\t Current Grid of Parameters is {'clf__C': 1, 'clf__penalty': 'none', 'clf__solver': 'saga', 'lasso__estimator__C': 0.06}\n",
      "\n",
      "\u001b[1mROC Train is 0.6331, ROC Test is 0.5596\u001b[0m\n",
      "Pipeline(steps=[('lasso',\n",
      "                 SelectFromModel(estimator=LogisticRegression(C=0.06,\n",
      "                                                              class_weight='balanced',\n",
      "                                                              penalty='l1',\n",
      "                                                              random_state=42,\n",
      "                                                              solver='liblinear'))),\n",
      "                ('clf',\n",
      "                 LogisticRegression(C=1, class_weight='balanced',\n",
      "                                    penalty='none', random_state=42,\n",
      "                                    solver='saga'))])\n",
      "execution time (min)= 0.4  finished at  2020-08-24 18:26:18.560468\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diz_params</th>\n",
       "      <th>degree_overfitting(%)</th>\n",
       "      <th>Train_AUC</th>\n",
       "      <th>Test_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'clf__C': 1, 'clf__penalty': 'none', 'clf__so...</td>\n",
       "      <td>7.35</td>\n",
       "      <td>0.6331</td>\n",
       "      <td>0.5596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'clf__C': 1, 'clf__penalty': 'none', 'clf__so...</td>\n",
       "      <td>6.94</td>\n",
       "      <td>0.6286</td>\n",
       "      <td>0.5592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'clf__C': 1, 'clf__penalty': 'none', 'clf__so...</td>\n",
       "      <td>6.24</td>\n",
       "      <td>0.6215</td>\n",
       "      <td>0.5591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'clf__C': 1, 'clf__penalty': 'none', 'clf__so...</td>\n",
       "      <td>5.89</td>\n",
       "      <td>0.6131</td>\n",
       "      <td>0.5542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'clf__C': 1, 'clf__penalty': 'none', 'clf__so...</td>\n",
       "      <td>4.57</td>\n",
       "      <td>0.5998</td>\n",
       "      <td>0.5541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          diz_params  degree_overfitting(%)  \\\n",
       "5  {'clf__C': 1, 'clf__penalty': 'none', 'clf__so...                   7.35   \n",
       "4  {'clf__C': 1, 'clf__penalty': 'none', 'clf__so...                   6.94   \n",
       "3  {'clf__C': 1, 'clf__penalty': 'none', 'clf__so...                   6.24   \n",
       "2  {'clf__C': 1, 'clf__penalty': 'none', 'clf__so...                   5.89   \n",
       "1  {'clf__C': 1, 'clf__penalty': 'none', 'clf__so...                   4.57   \n",
       "\n",
       "   Train_AUC  Test_AUC  \n",
       "5     0.6331    0.5596  \n",
       "4     0.6286    0.5592  \n",
       "3     0.6215    0.5591  \n",
       "2     0.6131    0.5542  \n",
       "1     0.5998    0.5541  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Grid Search without Cross Validation\n",
    "md5_final_list_C= list(md5_reduced_lasso_final.index)\n",
    "\n",
    "logi= Pipeline([\n",
    "      ('lasso', SelectFromModel(LogisticRegression(penalty='l1' ,random_state= 42, class_weight='balanced', solver= 'liblinear' ) )), \n",
    "      ('clf', LogisticRegression(random_state=42, class_weight='balanced' ), )   \n",
    "                        ])\n",
    "\n",
    "\n",
    "md5_param_grid_lasso =  [    {\n",
    "                'lasso__estimator__C': md5_final_list_C,\n",
    "                 'clf__penalty': ['none'], \n",
    "                'clf__solver': ['saga' ],\n",
    "                'clf__C': [1] # no needed, penalty is always set to 'none' bcs in the end we need to use a simple LR..\n",
    "                    }  ]\n",
    "\n",
    "\n",
    "###Â Without CV\n",
    "    \n",
    "    \n",
    "md5_grid_logistic_no_cv = run_model_no_cv(estimator=logi,\n",
    "                                        X_train= md5_orig_train_sample, \n",
    "                                        X_test= md5_orig_test_sample,\n",
    "                                        ytrain= ytrain_sample,\n",
    "                                        ytest= ytest_sample,\n",
    "                                        param_grid= md5_param_grid_lasso,\n",
    "                                        print_model=True)\n",
    "md5_grid_logistic_no_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_lasso__estimator__C</th>\n",
       "      <th>n_feats_selected</th>\n",
       "      <th>Train_AUC</th>\n",
       "      <th>Test_AUC</th>\n",
       "      <th>degree_overfitting(%)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ONLY MD5</th>\n",
       "      <td>0.06000</td>\n",
       "      <td>336</td>\n",
       "      <td>0.6331</td>\n",
       "      <td>0.5596</td>\n",
       "      <td>7.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ONLY MD5</th>\n",
       "      <td>0.05125</td>\n",
       "      <td>266</td>\n",
       "      <td>0.6286</td>\n",
       "      <td>0.5592</td>\n",
       "      <td>6.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ONLY MD5</th>\n",
       "      <td>0.04250</td>\n",
       "      <td>212</td>\n",
       "      <td>0.6215</td>\n",
       "      <td>0.5591</td>\n",
       "      <td>6.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ONLY MD5</th>\n",
       "      <td>0.03375</td>\n",
       "      <td>142</td>\n",
       "      <td>0.6131</td>\n",
       "      <td>0.5542</td>\n",
       "      <td>5.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ONLY MD5</th>\n",
       "      <td>0.02500</td>\n",
       "      <td>86</td>\n",
       "      <td>0.5998</td>\n",
       "      <td>0.5541</td>\n",
       "      <td>4.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          param_lasso__estimator__C  n_feats_selected  Train_AUC  Test_AUC  \\\n",
       "features                                                                     \n",
       "ONLY MD5                    0.06000               336     0.6331    0.5596   \n",
       "ONLY MD5                    0.05125               266     0.6286    0.5592   \n",
       "ONLY MD5                    0.04250               212     0.6215    0.5591   \n",
       "ONLY MD5                    0.03375               142     0.6131    0.5542   \n",
       "ONLY MD5                    0.02500                86     0.5998    0.5541   \n",
       "\n",
       "          degree_overfitting(%)  \n",
       "features                         \n",
       "ONLY MD5                   7.35  \n",
       "ONLY MD5                   6.94  \n",
       "ONLY MD5                   6.24  \n",
       "ONLY MD5                   5.89  \n",
       "ONLY MD5                   4.57  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md5_grid_logistic_no_cv['param_lasso__estimator__C']= \\\n",
    "                    md5_grid_logistic_no_cv['diz_params'].apply(lambda x: x['lasso__estimator__C'] )\n",
    "\n",
    "\n",
    "md5_final_complete_results= {}  #combining results_grids and features_selected to have a complete summary in one single df\n",
    "\n",
    "md5_features_selected.index.name= 'param_lasso__estimator__C'\n",
    "md5_final_complete_results= md5_features_selected.reset_index().merge(md5_grid_logistic_no_cv).sort_values(\n",
    "                                                                        by= 'Test_AUC', ascending= False)\n",
    "\n",
    "md5_final_complete_results= md5_final_complete_results[['param_lasso__estimator__C', 'n_feats_selected',\n",
    "                                                     'Train_AUC','Test_AUC', 'degree_overfitting(%)']]\n",
    "\n",
    "md5_final_complete_results\n",
    "\n",
    "\n",
    "md5_final_complete_results['features']= 'ONLY MD5'\n",
    "md5_final_complete_results.set_index('features', inplace= True)\n",
    "\n",
    "md5_final_complete_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Using only dsp features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial features = 3656\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_feats_selected</th>\n",
       "      <th>list_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0500</th>\n",
       "      <td>127</td>\n",
       "      <td>[2, 3, 4, 31, 84, 85, 87, 157, 219, 284, 358, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0625</th>\n",
       "      <td>181</td>\n",
       "      <td>[2, 3, 4, 31, 62, 84, 85, 87, 157, 219, 284, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0750</th>\n",
       "      <td>259</td>\n",
       "      <td>[1, 2, 4, 31, 61, 62, 84, 87, 128, 157, 195, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0875</th>\n",
       "      <td>342</td>\n",
       "      <td>[1, 2, 3, 4, 31, 48, 61, 62, 84, 87, 91, 126, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>412</td>\n",
       "      <td>[1, 2, 3, 4, 31, 48, 61, 62, 84, 87, 91, 126, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        n_feats_selected                                      list_features\n",
       "0.0500               127  [2, 3, 4, 31, 84, 85, 87, 157, 219, 284, 358, ...\n",
       "0.0625               181  [2, 3, 4, 31, 62, 84, 85, 87, 157, 219, 284, 3...\n",
       "0.0750               259  [1, 2, 4, 31, 61, 62, 84, 87, 128, 157, 195, 2...\n",
       "0.0875               342  [1, 2, 3, 4, 31, 48, 61, 62, 84, 87, 91, 126, ...\n",
       "0.1000               412  [1, 2, 3, 4, 31, 48, 61, 62, 84, 87, 91, 126, ..."
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_C_parameters =  np.linspace(0.05, 0.1, 5)  #np.arange(0.00125, 0.005, 5)  #list(np.linspace(0.001, 0.125, 4))  # or = [0.00050, 0.00075, 0.00100]\n",
    "\n",
    "dsp_features_selected= dsp_reduced_lasso_final= reduced_models_lasso(\n",
    "                                    values_C= list_C_parameters,\n",
    "                                    train= dsp_orig_train_sample,\n",
    "                                    ytrain= ytrain_sample,\n",
    "                                    random_state=42,\n",
    "                                    min_n_feats= 20,\n",
    "                                    max_n_feats= 500,\n",
    "                                    solver= 'liblinear')    \n",
    "\n",
    "dsp_reduced_lasso_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Initial X_train e X_test shapes are:  (30000, 3656) (10000, 3656) \u001b[0m \n",
      "\n",
      "\n",
      "\t \u001b[1mITERATION 1/5 \u001b[0m\n",
      "\t Current Grid of Parameters is {'clf__C': 1, 'clf__penalty': 'none', 'clf__solver': 'saga', 'lasso__estimator__C': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.6/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mROC Train is 0.6058, ROC Test is 0.5463\u001b[0m\n",
      "Pipeline(steps=[('lasso',\n",
      "                 SelectFromModel(estimator=LogisticRegression(C=0.05,\n",
      "                                                              class_weight='balanced',\n",
      "                                                              penalty='l1',\n",
      "                                                              random_state=42,\n",
      "                                                              solver='liblinear'))),\n",
      "                ('clf',\n",
      "                 LogisticRegression(C=1, class_weight='balanced',\n",
      "                                    penalty='none', random_state=42,\n",
      "                                    solver='saga'))])\n",
      "\n",
      "\t \u001b[1mITERATION 2/5 \u001b[0m\n",
      "\t Current Grid of Parameters is {'clf__C': 1, 'clf__penalty': 'none', 'clf__solver': 'saga', 'lasso__estimator__C': 0.0625}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.6/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mROC Train is 0.6232, ROC Test is 0.5509\u001b[0m\n",
      "Pipeline(steps=[('lasso',\n",
      "                 SelectFromModel(estimator=LogisticRegression(C=0.0625,\n",
      "                                                              class_weight='balanced',\n",
      "                                                              penalty='l1',\n",
      "                                                              random_state=42,\n",
      "                                                              solver='liblinear'))),\n",
      "                ('clf',\n",
      "                 LogisticRegression(C=1, class_weight='balanced',\n",
      "                                    penalty='none', random_state=42,\n",
      "                                    solver='saga'))])\n",
      "\n",
      "\t \u001b[1mITERATION 3/5 \u001b[0m\n",
      "\t Current Grid of Parameters is {'clf__C': 1, 'clf__penalty': 'none', 'clf__solver': 'saga', 'lasso__estimator__C': 0.075}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.6/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mROC Train is 0.6337, ROC Test is 0.5502\u001b[0m\n",
      "Pipeline(steps=[('lasso',\n",
      "                 SelectFromModel(estimator=LogisticRegression(C=0.075,\n",
      "                                                              class_weight='balanced',\n",
      "                                                              penalty='l1',\n",
      "                                                              random_state=42,\n",
      "                                                              solver='liblinear'))),\n",
      "                ('clf',\n",
      "                 LogisticRegression(C=1, class_weight='balanced',\n",
      "                                    penalty='none', random_state=42,\n",
      "                                    solver='saga'))])\n",
      "\n",
      "\t \u001b[1mITERATION 4/5 \u001b[0m\n",
      "\t Current Grid of Parameters is {'clf__C': 1, 'clf__penalty': 'none', 'clf__solver': 'saga', 'lasso__estimator__C': 0.0875}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.6/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mROC Train is 0.6433, ROC Test is 0.5474\u001b[0m\n",
      "Pipeline(steps=[('lasso',\n",
      "                 SelectFromModel(estimator=LogisticRegression(C=0.0875,\n",
      "                                                              class_weight='balanced',\n",
      "                                                              penalty='l1',\n",
      "                                                              random_state=42,\n",
      "                                                              solver='liblinear'))),\n",
      "                ('clf',\n",
      "                 LogisticRegression(C=1, class_weight='balanced',\n",
      "                                    penalty='none', random_state=42,\n",
      "                                    solver='saga'))])\n",
      "\n",
      "\t \u001b[1mITERATION 5/5 \u001b[0m\n",
      "\t Current Grid of Parameters is {'clf__C': 1, 'clf__penalty': 'none', 'clf__solver': 'saga', 'lasso__estimator__C': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.6/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mROC Train is 0.6502, ROC Test is 0.5494\u001b[0m\n",
      "Pipeline(steps=[('lasso',\n",
      "                 SelectFromModel(estimator=LogisticRegression(C=0.1,\n",
      "                                                              class_weight='balanced',\n",
      "                                                              penalty='l1',\n",
      "                                                              random_state=42,\n",
      "                                                              solver='liblinear'))),\n",
      "                ('clf',\n",
      "                 LogisticRegression(C=1, class_weight='balanced',\n",
      "                                    penalty='none', random_state=42,\n",
      "                                    solver='saga'))])\n",
      "execution time (min)= 2.3  finished at  2020-08-24 18:40:27.313166\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diz_params</th>\n",
       "      <th>degree_overfitting(%)</th>\n",
       "      <th>Train_AUC</th>\n",
       "      <th>Test_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'clf__C': 1, 'clf__penalty': 'none', 'clf__so...</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0.6232</td>\n",
       "      <td>0.5509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'clf__C': 1, 'clf__penalty': 'none', 'clf__so...</td>\n",
       "      <td>8.35</td>\n",
       "      <td>0.6337</td>\n",
       "      <td>0.5502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'clf__C': 1, 'clf__penalty': 'none', 'clf__so...</td>\n",
       "      <td>10.08</td>\n",
       "      <td>0.6502</td>\n",
       "      <td>0.5494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'clf__C': 1, 'clf__penalty': 'none', 'clf__so...</td>\n",
       "      <td>9.59</td>\n",
       "      <td>0.6433</td>\n",
       "      <td>0.5474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'clf__C': 1, 'clf__penalty': 'none', 'clf__so...</td>\n",
       "      <td>5.95</td>\n",
       "      <td>0.6058</td>\n",
       "      <td>0.5463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          diz_params  degree_overfitting(%)  \\\n",
       "2  {'clf__C': 1, 'clf__penalty': 'none', 'clf__so...                   7.23   \n",
       "3  {'clf__C': 1, 'clf__penalty': 'none', 'clf__so...                   8.35   \n",
       "5  {'clf__C': 1, 'clf__penalty': 'none', 'clf__so...                  10.08   \n",
       "4  {'clf__C': 1, 'clf__penalty': 'none', 'clf__so...                   9.59   \n",
       "1  {'clf__C': 1, 'clf__penalty': 'none', 'clf__so...                   5.95   \n",
       "\n",
       "   Train_AUC  Test_AUC  \n",
       "2     0.6232    0.5509  \n",
       "3     0.6337    0.5502  \n",
       "5     0.6502    0.5494  \n",
       "4     0.6433    0.5474  \n",
       "1     0.6058    0.5463  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Grid Search without Cross Validation\n",
    "dsp_final_list_C= list(dsp_reduced_lasso_final.index)\n",
    "\n",
    "logi= Pipeline([\n",
    "      ('lasso', SelectFromModel(LogisticRegression(penalty='l1' ,random_state= 42, class_weight='balanced', solver= 'liblinear' ) )), \n",
    "      ('clf', LogisticRegression(random_state=42, class_weight='balanced' ), )   \n",
    "                        ])\n",
    "\n",
    "\n",
    "dsp_param_grid_lasso =  [    {\n",
    "                'lasso__estimator__C': dsp_final_list_C,\n",
    "                 'clf__penalty': ['none'], \n",
    "                'clf__solver': ['saga' ],\n",
    "                'clf__C': [1] # no needed, penalty is always set to 'none' bcs in the end we need to use a simple LR..\n",
    "                    }  ]\n",
    "\n",
    "\n",
    "###Â Without CV\n",
    "    \n",
    "    \n",
    "dsp_grid_logistic_no_cv = run_model_no_cv(estimator=logi,\n",
    "                                        X_train= dsp_orig_train_sample, \n",
    "                                        X_test= dsp_orig_test_sample,\n",
    "                                        ytrain= ytrain_sample,\n",
    "                                        ytest= ytest_sample,\n",
    "                                        param_grid= dsp_param_grid_lasso,\n",
    "                                        print_model=True)\n",
    "dsp_grid_logistic_no_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_lasso__estimator__C</th>\n",
       "      <th>n_feats_selected</th>\n",
       "      <th>Train_AUC</th>\n",
       "      <th>Test_AUC</th>\n",
       "      <th>degree_overfitting(%)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>features</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ONLY DSP</th>\n",
       "      <td>0.0625</td>\n",
       "      <td>181</td>\n",
       "      <td>0.6232</td>\n",
       "      <td>0.5509</td>\n",
       "      <td>7.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ONLY DSP</th>\n",
       "      <td>0.0750</td>\n",
       "      <td>259</td>\n",
       "      <td>0.6337</td>\n",
       "      <td>0.5502</td>\n",
       "      <td>8.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ONLY DSP</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>412</td>\n",
       "      <td>0.6502</td>\n",
       "      <td>0.5494</td>\n",
       "      <td>10.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ONLY DSP</th>\n",
       "      <td>0.0875</td>\n",
       "      <td>342</td>\n",
       "      <td>0.6433</td>\n",
       "      <td>0.5474</td>\n",
       "      <td>9.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ONLY DSP</th>\n",
       "      <td>0.0500</td>\n",
       "      <td>127</td>\n",
       "      <td>0.6058</td>\n",
       "      <td>0.5463</td>\n",
       "      <td>5.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          param_lasso__estimator__C  n_feats_selected  Train_AUC  Test_AUC  \\\n",
       "features                                                                     \n",
       "ONLY DSP                     0.0625               181     0.6232    0.5509   \n",
       "ONLY DSP                     0.0750               259     0.6337    0.5502   \n",
       "ONLY DSP                     0.1000               412     0.6502    0.5494   \n",
       "ONLY DSP                     0.0875               342     0.6433    0.5474   \n",
       "ONLY DSP                     0.0500               127     0.6058    0.5463   \n",
       "\n",
       "          degree_overfitting(%)  \n",
       "features                         \n",
       "ONLY DSP                   7.23  \n",
       "ONLY DSP                   8.35  \n",
       "ONLY DSP                  10.08  \n",
       "ONLY DSP                   9.59  \n",
       "ONLY DSP                   5.95  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsp_grid_logistic_no_cv['param_lasso__estimator__C']= \\\n",
    "                    dsp_grid_logistic_no_cv['diz_params'].apply(lambda x: x['lasso__estimator__C'] )\n",
    "\n",
    "\n",
    "dsp_final_complete_results= {}  #combining results_grids and features_selected to have a complete summary in one single df\n",
    "\n",
    "dsp_features_selected.index.name= 'param_lasso__estimator__C'\n",
    "dsp_final_complete_results= dsp_features_selected.reset_index().merge(dsp_grid_logistic_no_cv).sort_values(\n",
    "                                                                        by= 'Test_AUC', ascending= False)\n",
    "\n",
    "dsp_final_complete_results= dsp_final_complete_results[['param_lasso__estimator__C', 'n_feats_selected',\n",
    "                                                     'Train_AUC','Test_AUC', 'degree_overfitting(%)']]\n",
    "\n",
    "\n",
    "dsp_final_complete_results['features']= 'ONLY DSP'\n",
    "dsp_final_complete_results.set_index('features', inplace= True)\n",
    "\n",
    "dsp_final_complete_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training RBM, Reconstruction Case\n",
    "- Here we are training the RBM with the label, and then using the imputed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_reconstruction_RBM(train_loader,\n",
    "                             VISIBLE_UNITS,\n",
    "                             BATCH_SIZE=64,\n",
    "                             HIDDEN_UNITS=128, \n",
    "                             CD_K=1, \n",
    "                             EPOCHS=60,\n",
    "                             use_cuda=False):\n",
    "    rbm = RBM(VISIBLE_UNITS, HIDDEN_UNITS, CD_K, use_cuda=CUDA)\n",
    "    loss = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        epoch_error = 0.0\n",
    "    \n",
    "        for batch in train_loader:\n",
    "            batch = batch.view(len(batch), VISIBLE_UNITS)  # flatten input data\n",
    "    \n",
    "            if CUDA:\n",
    "                batch = batch.cuda()\n",
    "    \n",
    "            batch_error = rbm.contrastive_divergence(batch)\n",
    "    \n",
    "            epoch_error += batch_error\n",
    "    \n",
    "        print('Epoch Error (epoch=%d): %.4f' % (epoch, epoch_error))\n",
    "        loss.append([epoch, epoch_error.item()])\n",
    "    return rbm, loss\n",
    "\n",
    "def generate_reconstruction(rbm,\n",
    "                             test_dataset,\n",
    "                             test_loader,\n",
    "                             HIDDEN_UNITS=128):\n",
    "    VISIBLE_UNITS = train_dataset.VISIBLE_UNITS\n",
    "    train_features = np.zeros((len(train_dataset), VISIBLE_UNITS))\n",
    "    train_labels = np.zeros(len(train_dataset))\n",
    "    test_features = np.zeros((len(test_dataset), VISIBLE_UNITS))\n",
    "    test_labels = np.zeros(len(test_dataset))\n",
    "    \n",
    "    for i, batch in enumerate(test_loader):\n",
    "        batch = batch.view(len(batch), VISIBLE_UNITS)  # flatten input data\n",
    "    \n",
    "        if CUDA:\n",
    "            batch = batch.cuda()\n",
    "    \n",
    "        test_features[i*BATCH_SIZE:i*BATCH_SIZE+len(batch)] = rbm.sample_visible(rbm.sample_hidden(batch))\n",
    "    \n",
    "    return test_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Error (epoch=0): 14658797.0000\n",
      "Epoch Error (epoch=1): 4367725.0000\n",
      "Epoch Error (epoch=2): 1434441.1250\n",
      "Epoch Error (epoch=3): 1431335.7500\n",
      "Epoch Error (epoch=4): 1317407.0000\n",
      "Epoch Error (epoch=5): 1199919.7500\n",
      "Epoch Error (epoch=6): 1110802.8750\n",
      "Epoch Error (epoch=7): 1059587.3750\n",
      "Epoch Error (epoch=8): 1031394.9375\n",
      "Epoch Error (epoch=9): 1018359.5625\n",
      "Epoch Error (epoch=10): 1001582.0625\n",
      "Epoch Error (epoch=11): 987331.2500\n",
      "Epoch Error (epoch=12): 971022.0625\n",
      "Epoch Error (epoch=13): 951235.0625\n",
      "Epoch Error (epoch=14): 929514.1875\n",
      "Epoch Error (epoch=15): 911978.7500\n",
      "Epoch Error (epoch=16): 900326.9375\n",
      "Epoch Error (epoch=17): 890321.0000\n",
      "Epoch Error (epoch=18): 882664.1250\n",
      "Epoch Error (epoch=19): 879451.5625\n",
      "Epoch Error (epoch=20): 870530.4375\n",
      "Epoch Error (epoch=21): 865978.0000\n",
      "Epoch Error (epoch=22): 860877.1250\n",
      "Epoch Error (epoch=23): 858169.8750\n",
      "Epoch Error (epoch=24): 853091.2500\n",
      "Epoch Error (epoch=25): 848196.6250\n",
      "Epoch Error (epoch=26): 847793.0625\n",
      "Epoch Error (epoch=27): 844543.0000\n",
      "Epoch Error (epoch=28): 840586.1250\n",
      "Epoch Error (epoch=29): 836492.3125\n",
      "Epoch Error (epoch=30): 834697.3750\n",
      "Epoch Error (epoch=31): 831339.5000\n",
      "Epoch Error (epoch=32): 830415.3750\n",
      "Epoch Error (epoch=33): 827249.5000\n",
      "Epoch Error (epoch=34): 824549.6875\n",
      "Epoch Error (epoch=35): 821791.1875\n",
      "Epoch Error (epoch=36): 821123.3125\n",
      "Epoch Error (epoch=37): 818198.7500\n",
      "Epoch Error (epoch=38): 817336.6250\n",
      "Epoch Error (epoch=39): 815124.5000\n",
      "Epoch Error (epoch=40): 812826.0000\n",
      "Epoch Error (epoch=41): 810981.0000\n",
      "Epoch Error (epoch=42): 809138.8750\n",
      "Epoch Error (epoch=43): 807769.7500\n",
      "Epoch Error (epoch=44): 805796.9375\n",
      "Epoch Error (epoch=45): 803488.2500\n",
      "Epoch Error (epoch=46): 802151.0625\n",
      "Epoch Error (epoch=47): 800089.8125\n",
      "Epoch Error (epoch=48): 798610.8750\n",
      "Epoch Error (epoch=49): 797096.5000\n",
      "Epoch Error (epoch=50): 795385.4375\n",
      "Epoch Error (epoch=51): 794273.6250\n",
      "Epoch Error (epoch=52): 792936.9375\n",
      "Epoch Error (epoch=53): 793433.8125\n",
      "Epoch Error (epoch=54): 790875.5625\n",
      "Epoch Error (epoch=55): 789607.5625\n",
      "Epoch Error (epoch=56): 788988.5625\n",
      "Epoch Error (epoch=57): 786570.1250\n",
      "Epoch Error (epoch=58): 786805.8125\n",
      "Epoch Error (epoch=59): 784833.5625\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = NonAddressableImputationDataset(train)\n",
    "test_dataset = NonAddressableImputationDataset(test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader= torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "rbm, losses = train_reconstruction_RBM(train_loader, \n",
    "                                       train_dataset.VISIBLE_UNITS)\n",
    "plot_loss(losses)\n",
    "test_features = \\\n",
    "  generate_reconstruction(rbm,\n",
    "                          test_dataset,\n",
    "                          test_loader)\n",
    "train_features = \\\n",
    "  generate_reconstruction(rbm,\n",
    "                          train_dataset,\n",
    "                          train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary Evaluation: Reconstruction\n",
    "- here i was not sure how to determine a cutoff probability for the imputed label. so i created one off of the distribution of reconstructed labels in the training set, \n",
    "    - frankly i am not sure whether this is a good practice or not, but figured it would give us an idea of how this performs\n",
    "- overall it appears that this is not the correct approach to go with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(train[Y].values, train_features[:, label_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5348187947629118"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test[Y].values, test_features[:, label_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
