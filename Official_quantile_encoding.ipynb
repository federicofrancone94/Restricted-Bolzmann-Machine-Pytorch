{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported Spark Context and Spark Configuration\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "from src.SparkEnv import sparkSess\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import DataFrameStatFunctions as statFunc\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, FloatType\n",
    "from pyspark.sql.functions import UserDefinedFunction, udf, struct\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = \"hdfs:///input\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 items\n",
      "-rw-r--r--   1 hadoop hadoop    6260261 2020-08-18 16:39 hdfs:///input/featureIndex.csv\n",
      "drwxr-xr-x   - hadoop hadoop          0 2020-08-18 16:38 hdfs:///input/feature_data\n",
      "-rw-r--r--   1 hadoop hadoop 2530566106 2020-08-18 16:41 hdfs:///input/ff_dsp_non_addressable_model_aff_tbl.csv\n",
      "drwxr-xr-x   - hadoop hadoop          0 2020-08-18 16:40 hdfs:///input/gdsa_conversion_data\n",
      "drwxr-xr-x   - hadoop hadoop          0 2020-08-18 16:40 hdfs:///input/gdsa_data\n",
      "-rw-r--r--   1 hadoop hadoop 1054158304 2020-08-18 16:39 hdfs:///input/md5_match_data.csv\n",
      "drwxr-xr-x   - hadoop hadoop          0 2020-08-18 16:39 hdfs:///input/user_requests_10mil\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls $pre/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !s3-dist-cp --src=s3://gdsa-prague/dsp_LAL/data/ff_dsp_non_addressable_model_aff_tbl.csv.gz --dest=hdfs:///input/gdsa_data/ --outputCodec=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Affinity data in order to have continuous variables to play with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 items\n",
      "-rw-r--r--   1 hadoop hadoop    6260261 2020-08-18 16:39 hdfs:///input/featureIndex.csv\n",
      "drwxr-xr-x   - hadoop hadoop          0 2020-08-18 16:38 hdfs:///input/feature_data\n",
      "-rw-r--r--   1 hadoop hadoop 2530566106 2020-08-18 16:41 hdfs:///input/ff_dsp_non_addressable_model_aff_tbl.csv\n",
      "drwxr-xr-x   - hadoop hadoop          0 2020-08-18 16:40 hdfs:///input/gdsa_conversion_data\n",
      "drwxr-xr-x   - hadoop hadoop          0 2020-08-18 16:40 hdfs:///input/gdsa_data\n",
      "-rw-r--r--   1 hadoop hadoop 1054158304 2020-08-18 16:39 hdfs:///input/md5_match_data.csv\n",
      "drwxr-xr-x   - hadoop hadoop          0 2020-08-18 16:39 hdfs:///input/user_requests_10mil\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls $pre/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3048983"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_values = ['-99', '-98', -99, -98, '\\\\N', '\\\\\\\\N', 'Missing', 'missing', 'NA', '?', '.', 'NULL', '', ' ']\n",
    "\n",
    "\n",
    "affinity = \\\n",
    "      sparkSess.read.csv(f\"{pre}/ff_dsp_non_addressable_model_aff_tbl.csv\", header=True, nullValue= na_values)\n",
    "\n",
    "# acxiom.persist()\n",
    "\n",
    "affinity.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308\n",
      "root\n",
      " |-- EMAIL_ADDRESS_MD5: string (nullable = true)\n",
      " |-- SEG_100001: string (nullable = true)\n",
      " |-- SEG_100002: string (nullable = true)\n",
      " |-- SEG_100606: string (nullable = true)\n",
      " |-- SEG_100433: string (nullable = true)\n",
      " |-- SEG_100430: string (nullable = true)\n",
      " |-- SEG_100436: string (nullable = true)\n",
      "\n",
      "+--------------------+----------+----------+----------+----------+----------+----------+\n",
      "|   EMAIL_ADDRESS_MD5|SEG_100001|SEG_100002|SEG_100606|SEG_100433|SEG_100430|SEG_100436|\n",
      "+--------------------+----------+----------+----------+----------+----------+----------+\n",
      "|bfb1fd608bac28492...|       120|         1|         4|       578|       214|       252|\n",
      "|20f3c2f6be7db4633...|         0|         1|         1|         1|         1|         3|\n",
      "|3af755c5bf70c4f85...|         2|         0|         2|       116|        64|        23|\n",
      "|a8d63ac940c56d84c...|         0|         6|         1|         2|         2|         2|\n",
      "|66c3d68a3b9d452e5...|        87|         2|         8|        52|        79|        14|\n",
      "+--------------------+----------+----------+----------+----------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp= affinity.sample(withReplacement=False, fraction=0.0001, seed=42).select(affinity.columns[:8]).drop('ZETA_ID')\n",
    "\n",
    "\n",
    "print(temp.count())\n",
    "temp.printSchema()\n",
    "\n",
    "temp.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Default Pyspark puts all the fields as StringType(). I need to cast them as Float. Getting relevant quantiles for each variable and mapping them to a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SEG_100001\n",
      "Managed V\n",
      "\n",
      " SEG_100002\n",
      "Managed V\n",
      "\n",
      " SEG_100606\n",
      "Managed V\n",
      "\n",
      " SEG_100433\n",
      "Managed V\n",
      "\n",
      " SEG_100430\n",
      "Managed V\n",
      "\n",
      " SEG_100436\n",
      "Managed V\n"
     ]
    }
   ],
   "source": [
    "float_columns= []\n",
    "\n",
    "dict_relevant_percentiles= {}\n",
    "relevant_percentiles = list(np.arange(0.25, 1, 0.25)) #25th, 50th (median) and 75th\n",
    "\n",
    "for col in [col for col in temp.columns if col.startswith('SEG')]:\n",
    "    print('\\n', col)\n",
    "    try:\n",
    "        \n",
    "        temp= temp.withColumn(col, temp[col].cast(FloatType()))\n",
    "        float_columns.append(col)\n",
    "        \n",
    "        list_percentiles= temp.approxQuantile(col, relevant_percentiles, 0.01) ### NOTE: last parameter is the relative error: low values imply higher computations\n",
    "        \n",
    "        ### Adding the minimum: NOT NEEDED ANYMORE. The bins will be: -Inf, 25th, 50th, 75th, +Inf\n",
    "        ## Inserting the minimum: I need these for binning the continuous variables\n",
    "        #list_percentiles.insert(0, temp.agg(F.min(col).alias('min_'+col)).collect()[0]['min_'+col])\n",
    "        \n",
    "        dict_relevant_percentiles[col]= list_percentiles\n",
    "        print('Managed V')\n",
    "    except:\n",
    "        \n",
    "        print('Failed X')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- EMAIL_ADDRESS_MD5: string (nullable = true)\n",
      " |-- SEG_100001: float (nullable = true)\n",
      " |-- SEG_100002: float (nullable = true)\n",
      " |-- SEG_100606: float (nullable = true)\n",
      " |-- SEG_100433: float (nullable = true)\n",
      " |-- SEG_100430: float (nullable = true)\n",
      " |-- SEG_100436: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Values imputation with Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get continuous columns    -->   NOT NEEDED NOW, I ALREADY GOT THE LIST OF FLOATS\n",
    "# cont_cols = [f.name for f in df.schema.fields if isinstance(f.dataType, FloatType)]\n",
    "# cont_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SEG_100001': [3.0, 8.0, 21.0],\n",
       " 'SEG_100002': [0.0, 1.0, 4.0],\n",
       " 'SEG_100606': [1.0, 4.0, 11.0],\n",
       " 'SEG_100433': [37.0, 74.0, 127.0],\n",
       " 'SEG_100430': [25.0, 50.0, 96.0],\n",
       " 'SEG_100436': [6.0, 15.0, 37.0]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_relevant_percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_median= 1  # it's the index of the median. In this case it s the 3rd number of each list, after min and 25th\n",
    "\n",
    "for col in float_columns:\n",
    "    temp= temp.fillna(dict_relevant_percentiles[col][idx_median], subset= [col]) ## taking the middle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with one column (1st iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-----------------+\n",
      "|   EMAIL_ADDRESS_MD5|SEG_100001|binned_SEG_100001|\n",
      "+--------------------+----------+-----------------+\n",
      "|bfb1fd608bac28492...|     120.0|                3|\n",
      "|20f3c2f6be7db4633...|       0.0|                0|\n",
      "|3af755c5bf70c4f85...|       2.0|                0|\n",
      "|a8d63ac940c56d84c...|       0.0|                0|\n",
      "|66c3d68a3b9d452e5...|      87.0|                3|\n",
      "+--------------------+----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orig_col= 'SEG_100001'\n",
    "id_col= 'EMAIL_ADDRESS_MD5'\n",
    "bin_col= 'binned_' + orig_col\n",
    "\n",
    "bins= dict_relevant_percentiles[orig_col]\n",
    "bucketizer = Bucketizer(splits= [float('-Inf')]+ bins+ [float('Inf')] ,inputCol=orig_col, outputCol= bin_col)\n",
    "df_buck = bucketizer.setHandleInvalid(\"keep\").transform(temp.select([id_col , orig_col]))\n",
    "\n",
    "df_buck= df_buck.withColumn(bin_col, df_buck[bin_col].cast(IntegerType()))\n",
    "\n",
    "df_buck.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+---+---+---+\n",
      "|   EMAIL_ADDRESS_MD5|  0|  1|  2|  3|\n",
      "+--------------------+---+---+---+---+\n",
      "|65c68aca8845efa8c...|  0|  0|  0|  1|\n",
      "|8bd9486405b376a70...|  1|  0|  0|  0|\n",
      "|4144c442faf9dfb28...|  1|  0|  0|  0|\n",
      "|987d0fae534d672fa...|  0|  1|  0|  0|\n",
      "|878dc1fd37a319eda...|  0|  1|  0|  0|\n",
      "+--------------------+---+---+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prefix= bin_col\n",
    "\n",
    "# pivoted = df_buck.groupBy(\"cont_random_val\").pivot(\"buckets\").agg(F.lit(1)).fillna(0)\n",
    "\n",
    "pivoted = df_buck.groupBy(id_col).pivot(bin_col).agg(F.lit(1).alias(prefix)).fillna(0) #nothing changes\n",
    "pivoted.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+------------+------------+------------+\n",
      "|   EMAIL_ADDRESS_MD5|SEG_100001_0|SEG_100001_1|SEG_100001_2|SEG_100001_3|\n",
      "+--------------------+------------+------------+------------+------------+\n",
      "|4144c442faf9dfb28...|           1|           0|           0|           0|\n",
      "|65c68aca8845efa8c...|           0|           0|           0|           1|\n",
      "|8bd9486405b376a70...|           1|           0|           0|           0|\n",
      "|987d0fae534d672fa...|           0|           1|           0|           0|\n",
      "|878dc1fd37a319eda...|           0|           1|           0|           0|\n",
      "+--------------------+------------+------------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prefix= 'SEG_100001'\n",
    "\n",
    "for col in pivoted.columns[1:]:\n",
    "    pivoted = pivoted.withColumnRenamed(col, prefix + '_' + col)\n",
    "    \n",
    "pivoted.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SEG_100001_0': 'SEG_100001',\n",
       " 'SEG_100001_1': 'SEG_100001',\n",
       " 'SEG_100001_2': 'SEG_100001',\n",
       " 'SEG_100001_3': 'SEG_100001'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_col_names= dict(zip( list(pivoted.columns[1:]), ( (orig_col + ' ') *4).split(' ')))\n",
    "mapping_col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----------+----------+----------+----------+------------+------------+------------+\n",
      "|   EMAIL_ADDRESS_MD5|SEG_100002|SEG_100606|SEG_100433|SEG_100430|SEG_100436|SEG_100001_0|SEG_100001_1|SEG_100001_2|\n",
      "+--------------------+----------+----------+----------+----------+----------+------------+------------+------------+\n",
      "|bfb1fd608bac28492...|       1.0|       4.0|     578.0|     214.0|     252.0|           0|           0|           0|\n",
      "|20f3c2f6be7db4633...|       1.0|       1.0|       1.0|       1.0|       3.0|           1|           0|           0|\n",
      "|3af755c5bf70c4f85...|       0.0|       2.0|     116.0|      64.0|      23.0|           1|           0|           0|\n",
      "|a8d63ac940c56d84c...|       6.0|       1.0|       2.0|       2.0|       2.0|           1|           0|           0|\n",
      "|66c3d68a3b9d452e5...|       2.0|       8.0|      52.0|      79.0|      14.0|           0|           0|           0|\n",
      "|62a3e573761d3ea8c...|       1.0|      13.0|     126.0|      66.0|     240.0|           0|           0|           0|\n",
      "|dcd959b054d7aab41...|       0.0|      30.0|     240.0|     214.0|       9.0|           0|           0|           0|\n",
      "|15cc01993eb665e0d...|       4.0|      25.0|     192.0|      79.0|      77.0|           0|           0|           1|\n",
      "|6edbf0b62cd33dccc...|       2.0|       7.0|     162.0|     130.0|      57.0|           0|           0|           0|\n",
      "|f7883ed18e47f2eb7...|       0.0|       4.0|     107.0|      32.0|      49.0|           1|           0|           0|\n",
      "|91a43d562c5f963bd...|      37.0|       1.0|       2.0|       2.0|       2.0|           1|           0|           0|\n",
      "|d828bd300f4d419aa...|       9.0|       2.0|     222.0|     171.0|       5.0|           0|           1|           0|\n",
      "|bb8159ab9059b33a3...|       0.0|     434.0|     308.0|     413.0|      24.0|           0|           0|           0|\n",
      "|ea8c59750850b9462...|       0.0|       0.0|      99.0|      92.0|      10.0|           0|           1|           0|\n",
      "|18f2af44634724f8e...|       1.0|      11.0|     132.0|     141.0|       6.0|           0|           0|           0|\n",
      "|a602ed1e7c007d377...|       0.0|      11.0|     453.0|     122.0|       9.0|           0|           0|           0|\n",
      "|46894199f81b2a1e0...|       0.0|      64.0|      15.0|      16.0|       3.0|           0|           0|           0|\n",
      "|4f597f984b9ae159c...|       0.0|      52.0|     220.0|     308.0|      80.0|           0|           0|           1|\n",
      "|a363980a7072536a3...|       7.0|       8.0|     407.0|     230.0|     203.0|           0|           1|           0|\n",
      "|38613a80aeef23ad7...|       4.0|       4.0|      46.0|      25.0|       6.0|           1|           0|           0|\n",
      "+--------------------+----------+----------+----------+----------+----------+------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dummy_df = temp.drop(orig_col).join(pivoted.select(pivoted.columns[:-1]), on= id_col, how= 'left')\n",
    "\n",
    "dummy_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2nd iteration, to see if it works in a loop doing the OHE of different columns..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-----------------+\n",
      "|   EMAIL_ADDRESS_MD5|SEG_100002|binned_SEG_100002|\n",
      "+--------------------+----------+-----------------+\n",
      "|bfb1fd608bac28492...|       1.0|                2|\n",
      "|20f3c2f6be7db4633...|       1.0|                2|\n",
      "|3af755c5bf70c4f85...|       0.0|                1|\n",
      "|a8d63ac940c56d84c...|       6.0|                3|\n",
      "|66c3d68a3b9d452e5...|       2.0|                2|\n",
      "+--------------------+----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orig_col= 'SEG_100002'\n",
    "id_col= 'EMAIL_ADDRESS_MD5'\n",
    "bin_col= 'binned_' + orig_col\n",
    "\n",
    "bins= dict_relevant_percentiles[orig_col]\n",
    "bucketizer = Bucketizer(splits= [float('-Inf')]+ bins+ [float('Inf')] ,inputCol=orig_col, outputCol= bin_col)\n",
    "df_buck = bucketizer.setHandleInvalid(\"keep\").transform(temp.select([id_col , orig_col]))\n",
    "\n",
    "df_buck= df_buck.withColumn(bin_col, df_buck[bin_col].cast(IntegerType()))\n",
    "\n",
    "df_buck.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+---+---+\n",
      "|   EMAIL_ADDRESS_MD5|  1|  2|  3|\n",
      "+--------------------+---+---+---+\n",
      "|8bd9486405b376a70...|  1|  0|  0|\n",
      "|65c68aca8845efa8c...|  1|  0|  0|\n",
      "|4144c442faf9dfb28...|  1|  0|  0|\n",
      "|987d0fae534d672fa...|  1|  0|  0|\n",
      "|878dc1fd37a319eda...|  1|  0|  0|\n",
      "+--------------------+---+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prefix= bin_col\n",
    "\n",
    "# pivoted = df_buck.groupBy(\"cont_random_val\").pivot(\"buckets\").agg(F.lit(1)).fillna(0)\n",
    "\n",
    "pivoted = df_buck.groupBy(id_col).pivot(bin_col).agg(F.lit(1).alias(prefix)).fillna(0) #nothing changes\n",
    "pivoted.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+------------+------------+\n",
      "|   EMAIL_ADDRESS_MD5|SEG_100002_1|SEG_100002_2|SEG_100002_3|\n",
      "+--------------------+------------+------------+------------+\n",
      "|8bd9486405b376a70...|           1|           0|           0|\n",
      "|4144c442faf9dfb28...|           1|           0|           0|\n",
      "|65c68aca8845efa8c...|           1|           0|           0|\n",
      "|987d0fae534d672fa...|           1|           0|           0|\n",
      "|878dc1fd37a319eda...|           1|           0|           0|\n",
      "+--------------------+------------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prefix= 'SEG_100002'\n",
    "\n",
    "for col in pivoted.columns[1:]:\n",
    "    pivoted = pivoted.withColumnRenamed(col, prefix + '_' + col)\n",
    "    \n",
    "pivoted.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMAIL_ADDRESS_MD5</th>\n",
       "      <th>SEG_100606</th>\n",
       "      <th>SEG_100433</th>\n",
       "      <th>SEG_100430</th>\n",
       "      <th>SEG_100436</th>\n",
       "      <th>SEG_100001_0</th>\n",
       "      <th>SEG_100001_1</th>\n",
       "      <th>SEG_100001_2</th>\n",
       "      <th>SEG_100002_1</th>\n",
       "      <th>SEG_100002_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bfb1fd608bac2849224a93caf553ac07</td>\n",
       "      <td>4.0</td>\n",
       "      <td>578.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20f3c2f6be7db4633ed7df028e96b689</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3af755c5bf70c4f85b30c9af929d66cc</td>\n",
       "      <td>2.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a8d63ac940c56d84c13c25a107f5bffa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66c3d68a3b9d452e56887cab33d72fb2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  EMAIL_ADDRESS_MD5  SEG_100606  SEG_100433  SEG_100430  \\\n",
       "0  bfb1fd608bac2849224a93caf553ac07         4.0       578.0       214.0   \n",
       "1  20f3c2f6be7db4633ed7df028e96b689         1.0         1.0         1.0   \n",
       "2  3af755c5bf70c4f85b30c9af929d66cc         2.0       116.0        64.0   \n",
       "3  a8d63ac940c56d84c13c25a107f5bffa         1.0         2.0         2.0   \n",
       "4  66c3d68a3b9d452e56887cab33d72fb2         8.0        52.0        79.0   \n",
       "\n",
       "   SEG_100436  SEG_100001_0  SEG_100001_1  SEG_100001_2  SEG_100002_1  \\\n",
       "0       252.0             0             0             0             0   \n",
       "1         3.0             1             0             0             0   \n",
       "2        23.0             1             0             0             1   \n",
       "3         2.0             1             0             0             0   \n",
       "4        14.0             0             0             0             0   \n",
       "\n",
       "   SEG_100002_2  \n",
       "0             1  \n",
       "1             1  \n",
       "2             0  \n",
       "3             0  \n",
       "4             1  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## It works correctly!!\n",
    "\n",
    "final_dummy = dummy_df.drop(orig_col).join(pivoted.select(pivoted.columns[:-1]), on= id_col, how= 'left')\n",
    "\n",
    "final_dummy.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automating the whole process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_columns= []\n",
    "\n",
    "dict_relevant_percentiles= {}\n",
    "relevant_percentiles = list(np.arange(0.25, 1, 0.25)) #25th, 50th (median) and 75th\n",
    "\n",
    "potential_float_columns= [col for col in temp.columns if col.startswith('SEG')]\n",
    "\n",
    "def cast_and_get_quantiles(df, potential_float_columns):\n",
    "    \n",
    "    temp= df ## naming convention\n",
    "    for col in potential_float_columns:\n",
    "        print('\\n', col)\n",
    "        try:\n",
    "\n",
    "            temp= temp.withColumn(col, temp[col].cast(FloatType()))\n",
    "            float_columns.append(col)\n",
    "\n",
    "            list_percentiles= temp.approxQuantile(col, relevant_percentiles, 0.01) ### NOTE: last parameter is the relative error: low values imply higher computations\n",
    "\n",
    "            ### Adding the minimum: NOT NEEDED ANYMORE. The bins will be: -Inf, 25th, 50th, 75th, +Inf\n",
    "            ## Inserting the minimum: I need these for binning the continuous variables\n",
    "            #list_percentiles.insert(0, temp.agg(F.min(col).alias('min_'+col)).collect()[0]['min_'+col])\n",
    "        \n",
    "            dict_relevant_percentiles[col]= list_percentiles\n",
    "            print('Managed V')\n",
    "        except:\n",
    "\n",
    "            print('Failed X')\n",
    "            pass\n",
    "        \n",
    "    return (temp, dict_relevant_percentiles, float_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SEG_100001\n",
      "Managed V\n",
      "\n",
      " SEG_100002\n",
      "Managed V\n",
      "\n",
      " SEG_100606\n",
      "Managed V\n",
      "\n",
      " SEG_100433\n",
      "Managed V\n",
      "\n",
      " SEG_100430\n",
      "Managed V\n",
      "\n",
      " SEG_100436\n",
      "Managed V\n"
     ]
    }
   ],
   "source": [
    "df, dict_relevant_percentiles, float_columns= cast_and_get_quantiles(df= temp, \n",
    "                                                                     potential_float_columns= potential_float_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----------+----------+----------+----------+----------+\n",
      "|   EMAIL_ADDRESS_MD5|SEG_100001|SEG_100002|SEG_100606|SEG_100433|SEG_100430|SEG_100436|\n",
      "+--------------------+----------+----------+----------+----------+----------+----------+\n",
      "|bfb1fd608bac28492...|     120.0|       1.0|       4.0|     578.0|     214.0|     252.0|\n",
      "|20f3c2f6be7db4633...|       0.0|       1.0|       1.0|       1.0|       1.0|       3.0|\n",
      "|3af755c5bf70c4f85...|       2.0|       0.0|       2.0|     116.0|      64.0|      23.0|\n",
      "|a8d63ac940c56d84c...|       0.0|       6.0|       1.0|       2.0|       2.0|       2.0|\n",
      "|66c3d68a3b9d452e5...|      87.0|       2.0|       8.0|      52.0|      79.0|      14.0|\n",
      "+--------------------+----------+----------+----------+----------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_bucketize_dummy(df, initial_dummy_df, float_columns,   \n",
    "                         dict_relevant_percentiles,\n",
    "                         relevant_percentiles = list(np.arange(0.25, 1, 0.25)), \n",
    "                         idx_median= 1,\n",
    "                         id_col= 'EMAIL_ADDRESS_MD5'):\n",
    "\n",
    "\n",
    "#     idx_median= 1  # it's the index of the median. In this case it s the 2nd number of each list, after  25th\n",
    "    \n",
    "    temp= df ## naming convention\n",
    "    final_dummy_df= initial_dummy_df\n",
    "    \n",
    "    final_mapping_names= {}\n",
    "    \n",
    "    for col in float_columns:\n",
    "        \n",
    "        prefix= orig_col= col\n",
    "        \n",
    "        temp= temp.fillna(dict_relevant_percentiles[col][idx_median], subset= [col]) ## taking the middle\n",
    "\n",
    "\n",
    "        bin_col= 'binned_' + orig_col\n",
    "\n",
    "        bins= dict_relevant_percentiles[orig_col]\n",
    "        bucketizer = Bucketizer(splits= [float('-Inf')] + bins+ [float('Inf')] ,inputCol=orig_col, outputCol= bin_col)\n",
    "        df_buck = bucketizer.setHandleInvalid(\"keep\").transform(temp.select([id_col , orig_col]))\n",
    "\n",
    "        df_buck= df_buck.withColumn(bin_col, df_buck[bin_col].cast(IntegerType()))\n",
    "        \n",
    "\n",
    "        # pivoted = df_buck.groupBy(\"cont_random_val\").pivot(\"buckets\").agg(F.lit(1)).fillna(0)\n",
    "\n",
    "        pivoted = df_buck.groupBy(id_col).pivot(bin_col).agg(F.lit(1).alias(prefix)).fillna(0) \n",
    "\n",
    "        for col in pivoted.columns[1:]:\n",
    "            pivoted = pivoted.withColumnRenamed(col, prefix + '_' + col)\n",
    "            \n",
    "        mapping_col_names= dict(zip( list(pivoted.columns[1:]), ( (orig_col + ' ') *4).split(' ')))\n",
    "\n",
    "        final_mapping_names.update(mapping_col_names)\n",
    "        \n",
    "        final_dummy_df= final_dummy_df.drop(orig_col).join(pivoted.select(pivoted.columns[:-1]), on= id_col, how= 'left')\n",
    "\n",
    "\n",
    "    return (final_dummy_df, final_mapping_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df, final_mapping_names= impute_bucketize_dummy(df= df, \n",
    "                                                      initial_dummy_df=df,\n",
    "                                                      float_columns= float_columns,   \n",
    "                                                         dict_relevant_percentiles= dict_relevant_percentiles,\n",
    "                                                         relevant_percentiles = list(np.arange(0.25, 1, 0.25)), \n",
    "                                                         idx_median= 2,\n",
    "                                                         id_col= 'EMAIL_ADDRESS_MD5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SEG_100001_0': 'SEG_100001',\n",
       " 'SEG_100001_1': 'SEG_100001',\n",
       " 'SEG_100001_2': 'SEG_100001',\n",
       " 'SEG_100001_3': 'SEG_100001',\n",
       " 'SEG_100002_1': 'SEG_100002',\n",
       " 'SEG_100002_2': 'SEG_100002',\n",
       " 'SEG_100002_3': 'SEG_100002',\n",
       " 'SEG_100606_0': 'SEG_100606',\n",
       " 'SEG_100606_1': 'SEG_100606',\n",
       " 'SEG_100606_2': 'SEG_100606',\n",
       " 'SEG_100606_3': 'SEG_100606',\n",
       " 'SEG_100433_0': 'SEG_100433',\n",
       " 'SEG_100433_1': 'SEG_100433',\n",
       " 'SEG_100433_2': 'SEG_100433',\n",
       " 'SEG_100433_3': 'SEG_100433',\n",
       " 'SEG_100430_0': 'SEG_100430',\n",
       " 'SEG_100430_1': 'SEG_100430',\n",
       " 'SEG_100430_2': 'SEG_100430',\n",
       " 'SEG_100430_3': 'SEG_100430',\n",
       " 'SEG_100436_0': 'SEG_100436',\n",
       " 'SEG_100436_1': 'SEG_100436',\n",
       " 'SEG_100436_2': 'SEG_100436',\n",
       " 'SEG_100436_3': 'SEG_100436'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_mapping_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(EMAIL_ADDRESS_MD5='bfb1fd608bac2849224a93caf553ac07', SEG_100001_0=0, SEG_100001_1=0, SEG_100001_2=0, SEG_100002_1=0, SEG_100002_2=1, SEG_100606_0=0, SEG_100606_1=0, SEG_100606_2=1, SEG_100433_0=0, SEG_100433_1=0, SEG_100433_2=0, SEG_100430_0=0, SEG_100430_1=0, SEG_100430_2=0, SEG_100436_0=0, SEG_100436_1=0, SEG_100436_2=0),\n",
       " Row(EMAIL_ADDRESS_MD5='20f3c2f6be7db4633ed7df028e96b689', SEG_100001_0=1, SEG_100001_1=0, SEG_100001_2=0, SEG_100002_1=0, SEG_100002_2=1, SEG_100606_0=0, SEG_100606_1=1, SEG_100606_2=0, SEG_100433_0=1, SEG_100433_1=0, SEG_100433_2=0, SEG_100430_0=1, SEG_100430_1=0, SEG_100430_2=0, SEG_100436_0=1, SEG_100436_1=0, SEG_100436_2=0)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_df.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EMAIL_ADDRESS_MD5',\n",
       " 'SEG_100001_0',\n",
       " 'SEG_100001_1',\n",
       " 'SEG_100001_2',\n",
       " 'SEG_100002_1',\n",
       " 'SEG_100002_2',\n",
       " 'SEG_100606_0',\n",
       " 'SEG_100606_1',\n",
       " 'SEG_100606_2',\n",
       " 'SEG_100433_0',\n",
       " 'SEG_100433_1',\n",
       " 'SEG_100433_2',\n",
       " 'SEG_100430_0',\n",
       " 'SEG_100430_1',\n",
       " 'SEG_100430_2',\n",
       " 'SEG_100436_0',\n",
       " 'SEG_100436_1',\n",
       " 'SEG_100436_2']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+------------+------------+------------+------------+\n",
      "|   EMAIL_ADDRESS_MD5|SEG_100001_0|SEG_100001_1|SEG_100001_2|SEG_100002_1|SEG_100002_2|\n",
      "+--------------------+------------+------------+------------+------------+------------+\n",
      "|bfb1fd608bac28492...|           0|           0|           0|           0|           1|\n",
      "|20f3c2f6be7db4633...|           1|           0|           0|           0|           1|\n",
      "|3af755c5bf70c4f85...|           1|           0|           0|           1|           0|\n",
      "+--------------------+------------+------------+------------+------------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dummy_df.select(['EMAIL_ADDRESS_MD5',\n",
    "                 'SEG_100001_0',\n",
    "                 'SEG_100001_1',\n",
    "                 'SEG_100001_2',\n",
    "                 'SEG_100002_1',\n",
    "                 'SEG_100002_2']).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMAIL_ADDRESS_MD5</th>\n",
       "      <th>SEG_100001_0</th>\n",
       "      <th>SEG_100001_1</th>\n",
       "      <th>SEG_100001_2</th>\n",
       "      <th>SEG_100002_1</th>\n",
       "      <th>SEG_100002_2</th>\n",
       "      <th>SEG_100606_0</th>\n",
       "      <th>SEG_100606_1</th>\n",
       "      <th>SEG_100606_2</th>\n",
       "      <th>SEG_100433_0</th>\n",
       "      <th>SEG_100433_1</th>\n",
       "      <th>SEG_100433_2</th>\n",
       "      <th>SEG_100430_0</th>\n",
       "      <th>SEG_100430_1</th>\n",
       "      <th>SEG_100430_2</th>\n",
       "      <th>SEG_100436_0</th>\n",
       "      <th>SEG_100436_1</th>\n",
       "      <th>SEG_100436_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bfb1fd608bac2849224a93caf553ac07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20f3c2f6be7db4633ed7df028e96b689</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3af755c5bf70c4f85b30c9af929d66cc</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a8d63ac940c56d84c13c25a107f5bffa</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66c3d68a3b9d452e56887cab33d72fb2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  EMAIL_ADDRESS_MD5  SEG_100001_0  SEG_100001_1  SEG_100001_2  \\\n",
       "0  bfb1fd608bac2849224a93caf553ac07             0             0             0   \n",
       "1  20f3c2f6be7db4633ed7df028e96b689             1             0             0   \n",
       "2  3af755c5bf70c4f85b30c9af929d66cc             1             0             0   \n",
       "3  a8d63ac940c56d84c13c25a107f5bffa             1             0             0   \n",
       "4  66c3d68a3b9d452e56887cab33d72fb2             0             0             0   \n",
       "\n",
       "   SEG_100002_1  SEG_100002_2  SEG_100606_0  SEG_100606_1  SEG_100606_2  \\\n",
       "0             0             1             0             0             1   \n",
       "1             0             1             0             1             0   \n",
       "2             1             0             0             1             0   \n",
       "3             0             0             0             1             0   \n",
       "4             0             1             0             0             1   \n",
       "\n",
       "   SEG_100433_0  SEG_100433_1  SEG_100433_2  SEG_100430_0  SEG_100430_1  \\\n",
       "0             0             0             0             0             0   \n",
       "1             1             0             0             1             0   \n",
       "2             0             0             1             0             0   \n",
       "3             1             0             0             1             0   \n",
       "4             0             1             0             0             0   \n",
       "\n",
       "   SEG_100430_2  SEG_100436_0  SEG_100436_1  SEG_100436_2  \n",
       "0             0             0             0             0  \n",
       "1             0             1             0             0  \n",
       "2             1             0             0             1  \n",
       "3             0             1             0             0  \n",
       "4             1             0             1             0  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Final Display with all the columns\n",
    "\n",
    "dummy_df.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
